{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import sys\n",
    "import glob\n",
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import lightning as L\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score\n",
    "\n",
    "from data_module.data_module import ALDataModule_v1\n",
    "from model.classifier_model import Classifier1DMaxPoolBNModel, Classifier1D\n",
    "from utils.model_utils import unwrap_model\n",
    "\n",
    "from config.optimizer_param_config import optimizer_param_dict\n",
    "from config.channel_param_config import channel_param_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser(description=\"\", formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n",
    "\n",
    "parser.add_argument(\"-tl\", \"--train_limit_data\", type=int, default=1000,\n",
    "                    help=f\"Used for limit the number of data in train data, -1 mean no limit\")\n",
    "\n",
    "parser.add_argument(\"-cn\", \"--class_num\", type=int, default=8,\n",
    "                    help=f\"Number of class num use to train\")\n",
    "\n",
    "parser.add_argument(\"--target_class\", type=int, default=3,\n",
    "                    help=f\"Number of class num use to train\")\n",
    "\n",
    "parser.add_argument(\"--target_class_data_num\", type=int, default=10,\n",
    "                    help=f\"Number of data for the target class to train\")\n",
    "\n",
    "parser.add_argument(\"-m\", \"--model_name\", type=str, default=\"4cnn_64\",\n",
    "                    help=f\"Config name of model used for training\")\n",
    "\n",
    "parser.add_argument(\"-r\", \"--random_seed\", type=int, default=42,\n",
    "                    help=f\"Random Seed\")\n",
    "\n",
    "parser.add_argument(\"--eval_mode\", type=int, default=0,\n",
    "                    help=f\"Eval all models\")\n",
    "\n",
    "parser.add_argument(\"--patience\", type=int, default=200,\n",
    "                    help=f\"Early stopping patience\")\n",
    "\n",
    "if os.path.basename(sys.argv[0]) == 'ipykernel_launcher.py':\n",
    "    args = parser.parse_args(args=[])\n",
    "else:\n",
    "    args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_module():\n",
    "    L.seed_everything(42)\n",
    "    print(\"args.target_class, args.target_class_data_num\", args.target_class, args.target_class_data_num)\n",
    "    data_module = ALDataModule_v1(dataset_path=dataset_path, batch_size=512, prefix=\"torso_\", postfix=\"_fft\")\n",
    "    data_module.limit_and_set_train_data(data_module._train_data, data_module._train_label, limit_number=args.train_limit_data)\n",
    "    train_data, train_label = data_module.reduce_one_class_number(data_module.train_data, data_module.train_label, target_class=args.target_class, target_class_data_num=args.target_class_data_num)\n",
    "    val_data, val_label = data_module.reduce_one_class_number(data_module.val_data, data_module.val_label, target_class=args.target_class, target_class_data_num=args.target_class_data_num)\n",
    "    test_data, test_label = data_module.reduce_one_class_number(data_module.test_data, data_module.test_label, target_class=args.target_class, target_class_data_num=args.target_class_data_num)\n",
    "    \n",
    "    data_module.set_train_val_test_pred_data(\n",
    "        train_data = train_data,\n",
    "        train_label = train_label,\n",
    "        val_data = val_data,\n",
    "        val_label = val_label,\n",
    "        test_data = test_data,\n",
    "        test_label = test_label,\n",
    "        pred_data = test_data,\n",
    "    )\n",
    "    \n",
    "    print(np.unique(data_module.train_label, return_counts=True))\n",
    "    print(np.unique(data_module.val_label, return_counts=True))\n",
    "    print(np.unique(data_module.test_label, return_counts=True))\n",
    "\n",
    "    return data_module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = f\"dataset/processed_concat_data_{args.class_num}_labels\"\n",
    "\n",
    "log_save_dir = \"lightning_logs\"\n",
    "log_save_name = \"20_AL_train_unbalance/{}-{}-{}-{}-{}-{}-{}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_acc_from_save_folder(save_model_folder):\n",
    "    save_model_dir = os.path.join(log_save_dir, save_model_folder)\n",
    "    \n",
    "    weight = glob.glob(os.path.join(save_model_dir, \"version_0\", \"checkpoints\", \"*.ckpt\"))[0]\n",
    "\n",
    "    net = Classifier1DMaxPoolBNModel.load_from_checkpoint(weight)\n",
    "    data_module = create_data_module()\n",
    "\n",
    "    trainer = L.Trainer()\n",
    "    trainer.test(model=net, datamodule=data_module, verbose=False)\n",
    "    test_acc = trainer.logged_metrics[\"test_acc\"]\n",
    "\n",
    "    # Calculate target class TPR\n",
    "    output = trainer.predict(model=net, datamodule=data_module)\n",
    "    pred = torch.argmax(torch.concat(output), dim=1)\n",
    "    gt = list(map(lambda x: x[1], iter(data_module.test_dataloader())))\n",
    "    \n",
    "    gt_ravel = np.concatenate(list(map(lambda x: x.numpy(), gt)))\n",
    "    target_class_idx = gt_ravel == args.target_class - 1\n",
    "    \n",
    "    pred_ravel = pred.numpy()\n",
    "    target_class_pred_idx = pred_ravel == args.target_class - 1\n",
    "    target_class_tpr = np.sum(target_class_pred_idx&target_class_idx) / np.sum(target_class_idx)\n",
    "\n",
    "    print(target_class_tpr)\n",
    "    print(\"Error number\", (gt_ravel!=pred_ravel).sum())\n",
    "\n",
    "    return test_acc, target_class_tpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "limit_and_set_train_data limit_number= 1000\n",
      "reduce_one_class_number target_class= 3 target_class_data_num= 10\n",
      "reduce_one_class_number target_class= 3 target_class_data_num= 10\n",
      "reduce_one_class_number target_class= 3 target_class_data_num= 10\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000,   10, 1000, 1000, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1001,   10, 1000, 1000, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000,   10, 1000, 1000, 1000, 1000, 1000]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 120.21it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 150.40it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/pyth ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "limit_and_set_train_data limit_number= 1000\n",
      "reduce_one_class_number target_class= 3 target_class_data_num= 10\n",
      "reduce_one_class_number target_class= 3 target_class_data_num= 10\n",
      "reduce_one_class_number target_class= 3 target_class_data_num= 10\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000,   10, 1000, 1000, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1001,   10, 1000, 1000, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000,   10, 1000, 1000, 1000, 1000, 1000]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 155.88it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 176.67it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/pyth ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "limit_and_set_train_data limit_number= 1000\n",
      "reduce_one_class_number target_class= 3 target_class_data_num= 10\n",
      "reduce_one_class_number target_class= 3 target_class_data_num= 10\n",
      "reduce_one_class_number target_class= 3 target_class_data_num= 10\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000,   10, 1000, 1000, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1001,   10, 1000, 1000, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000,   10, 1000, 1000, 1000, 1000, 1000]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 101.14it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 121.53it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/pyth ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "limit_and_set_train_data limit_number= 1000\n",
      "reduce_one_class_number target_class= 3 target_class_data_num= 10\n",
      "reduce_one_class_number target_class= 3 target_class_data_num= 10\n",
      "reduce_one_class_number target_class= 3 target_class_data_num= 10\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000,   10, 1000, 1000, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1001,   10, 1000, 1000, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000,   10, 1000, 1000, 1000, 1000, 1000]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 142.33it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 179.41it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/pyth ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "limit_and_set_train_data limit_number= 1000\n",
      "reduce_one_class_number target_class= 3 target_class_data_num= 10\n",
      "reduce_one_class_number target_class= 3 target_class_data_num= 10\n",
      "reduce_one_class_number target_class= 3 target_class_data_num= 10\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000,   10, 1000, 1000, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1001,   10, 1000, 1000, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000,   10, 1000, 1000, 1000, 1000, 1000]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 144.57it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 126.60it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/pyth ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "limit_and_set_train_data limit_number= 1000\n",
      "reduce_one_class_number target_class= 3 target_class_data_num= 10\n",
      "reduce_one_class_number target_class= 3 target_class_data_num= 10\n",
      "reduce_one_class_number target_class= 3 target_class_data_num= 10\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000,   10, 1000, 1000, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1001,   10, 1000, 1000, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000,   10, 1000, 1000, 1000, 1000, 1000]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 143.39it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 183.89it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/pyth ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "limit_and_set_train_data limit_number= 1000\n",
      "reduce_one_class_number target_class= 3 target_class_data_num= 20\n",
      "reduce_one_class_number target_class= 3 target_class_data_num= 20\n",
      "reduce_one_class_number target_class= 3 target_class_data_num= 20\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000,   20, 1000, 1000, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1001,   20, 1000, 1000, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000,   20, 1000, 1000, 1000, 1000, 1000]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 150.42it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 188.46it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/pyth ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "limit_and_set_train_data limit_number= 1000\n",
      "reduce_one_class_number target_class= 3 target_class_data_num= 20\n",
      "reduce_one_class_number target_class= 3 target_class_data_num= 20\n",
      "reduce_one_class_number target_class= 3 target_class_data_num= 20\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000,   20, 1000, 1000, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1001,   20, 1000, 1000, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000,   20, 1000, 1000, 1000, 1000, 1000]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 104.00it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 170.15it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/pyth ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "limit_and_set_train_data limit_number= 1000\n",
      "reduce_one_class_number target_class= 3 target_class_data_num= 20\n",
      "reduce_one_class_number target_class= 3 target_class_data_num= 20\n",
      "reduce_one_class_number target_class= 3 target_class_data_num= 20\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000,   20, 1000, 1000, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1001,   20, 1000, 1000, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000,   20, 1000, 1000, 1000, 1000, 1000]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 141.93it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 143.57it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/pyth ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "limit_and_set_train_data limit_number= 1000\n",
      "reduce_one_class_number target_class= 3 target_class_data_num= 20\n",
      "reduce_one_class_number target_class= 3 target_class_data_num= 20\n",
      "reduce_one_class_number target_class= 3 target_class_data_num= 20\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000,   20, 1000, 1000, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1001,   20, 1000, 1000, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000,   20, 1000, 1000, 1000, 1000, 1000]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 102.07it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 154.38it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/pyth ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "limit_and_set_train_data limit_number= 1000\n",
      "reduce_one_class_number target_class= 3 target_class_data_num= 20\n",
      "reduce_one_class_number target_class= 3 target_class_data_num= 20\n",
      "reduce_one_class_number target_class= 3 target_class_data_num= 20\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000,   20, 1000, 1000, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1001,   20, 1000, 1000, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000,   20, 1000, 1000, 1000, 1000, 1000]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 145.23it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 183.53it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/pyth ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "limit_and_set_train_data limit_number= 1000\n",
      "reduce_one_class_number target_class= 3 target_class_data_num= 20\n",
      "reduce_one_class_number target_class= 3 target_class_data_num= 20\n",
      "reduce_one_class_number target_class= 3 target_class_data_num= 20\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000,   20, 1000, 1000, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1001,   20, 1000, 1000, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000,   20, 1000, 1000, 1000, 1000, 1000]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 142.88it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 128.25it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/pyth ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "limit_and_set_train_data limit_number= 1000\n",
      "reduce_one_class_number target_class= 3 target_class_data_num= 30\n",
      "reduce_one_class_number target_class= 3 target_class_data_num= 30\n",
      "reduce_one_class_number target_class= 3 target_class_data_num= 30\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000,   30, 1000, 1000, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1001,   30, 1000, 1000, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000,   30, 1000, 1000, 1000, 1000, 1000]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 119.57it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 137.80it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/pyth ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "limit_and_set_train_data limit_number= 1000\n",
      "reduce_one_class_number target_class= 3 target_class_data_num= 30\n",
      "reduce_one_class_number target_class= 3 target_class_data_num= 30\n",
      "reduce_one_class_number target_class= 3 target_class_data_num= 30\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000,   30, 1000, 1000, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1001,   30, 1000, 1000, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000,   30, 1000, 1000, 1000, 1000, 1000]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 138.80it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 179.49it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/pyth ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "limit_and_set_train_data limit_number= 1000\n",
      "reduce_one_class_number target_class= 3 target_class_data_num= 30\n",
      "reduce_one_class_number target_class= 3 target_class_data_num= 30\n",
      "reduce_one_class_number target_class= 3 target_class_data_num= 30\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000,   30, 1000, 1000, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1001,   30, 1000, 1000, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000,   30, 1000, 1000, 1000, 1000, 1000]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 150.71it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 122.93it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/pyth ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "limit_and_set_train_data limit_number= 1000\n",
      "reduce_one_class_number target_class= 3 target_class_data_num= 30\n",
      "reduce_one_class_number target_class= 3 target_class_data_num= 30\n",
      "reduce_one_class_number target_class= 3 target_class_data_num= 30\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000,   30, 1000, 1000, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1001,   30, 1000, 1000, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000,   30, 1000, 1000, 1000, 1000, 1000]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 164.41it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 179.98it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/pyth ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "limit_and_set_train_data limit_number= 1000\n",
      "reduce_one_class_number target_class= 3 target_class_data_num= 30\n",
      "reduce_one_class_number target_class= 3 target_class_data_num= 30\n",
      "reduce_one_class_number target_class= 3 target_class_data_num= 30\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000,   30, 1000, 1000, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1001,   30, 1000, 1000, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000,   30, 1000, 1000, 1000, 1000, 1000]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 109.06it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 163.93it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/pyth ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "limit_and_set_train_data limit_number= 1000\n",
      "reduce_one_class_number target_class= 3 target_class_data_num= 30\n",
      "reduce_one_class_number target_class= 3 target_class_data_num= 30\n",
      "reduce_one_class_number target_class= 3 target_class_data_num= 30\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000,   30, 1000, 1000, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1001,   30, 1000, 1000, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000,   30, 1000, 1000, 1000, 1000, 1000]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 134.19it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 162.11it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/pyth ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "limit_and_set_train_data limit_number= 1000\n",
      "reduce_one_class_number target_class= 3 target_class_data_num= 50\n",
      "reduce_one_class_number target_class= 3 target_class_data_num= 50\n",
      "reduce_one_class_number target_class= 3 target_class_data_num= 50\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000,   50, 1000, 1000, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1001,   50, 1000, 1000, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000,   50, 1000, 1000, 1000, 1000, 1000]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 113.15it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 127.92it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/pyth ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "limit_and_set_train_data limit_number= 1000\n",
      "reduce_one_class_number target_class= 3 target_class_data_num= 50\n",
      "reduce_one_class_number target_class= 3 target_class_data_num= 50\n",
      "reduce_one_class_number target_class= 3 target_class_data_num= 50\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000,   50, 1000, 1000, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1001,   50, 1000, 1000, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000,   50, 1000, 1000, 1000, 1000, 1000]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 111.66it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 161.54it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/pyth ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "limit_and_set_train_data limit_number= 1000\n",
      "reduce_one_class_number target_class= 3 target_class_data_num= 50\n",
      "reduce_one_class_number target_class= 3 target_class_data_num= 50\n",
      "reduce_one_class_number target_class= 3 target_class_data_num= 50\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000,   50, 1000, 1000, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1001,   50, 1000, 1000, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000,   50, 1000, 1000, 1000, 1000, 1000]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 143.57it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 180.32it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/pyth ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "limit_and_set_train_data limit_number= 1000\n",
      "reduce_one_class_number target_class= 3 target_class_data_num= 50\n",
      "reduce_one_class_number target_class= 3 target_class_data_num= 50\n",
      "reduce_one_class_number target_class= 3 target_class_data_num= 50\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000,   50, 1000, 1000, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1001,   50, 1000, 1000, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000,   50, 1000, 1000, 1000, 1000, 1000]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 114.53it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 134.18it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/pyth ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "limit_and_set_train_data limit_number= 1000\n",
      "reduce_one_class_number target_class= 3 target_class_data_num= 50\n",
      "reduce_one_class_number target_class= 3 target_class_data_num= 50\n",
      "reduce_one_class_number target_class= 3 target_class_data_num= 50\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000,   50, 1000, 1000, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1001,   50, 1000, 1000, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000,   50, 1000, 1000, 1000, 1000, 1000]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 122.16it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 176.45it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/pyth ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "limit_and_set_train_data limit_number= 1000\n",
      "reduce_one_class_number target_class= 3 target_class_data_num= 50\n",
      "reduce_one_class_number target_class= 3 target_class_data_num= 50\n",
      "reduce_one_class_number target_class= 3 target_class_data_num= 50\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000,   50, 1000, 1000, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1001,   50, 1000, 1000, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000,   50, 1000, 1000, 1000, 1000, 1000]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 150.40it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 137.23it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/pyth ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "limit_and_set_train_data limit_number= 1000\n",
      "reduce_one_class_number target_class= 3 target_class_data_num= 100\n",
      "reduce_one_class_number target_class= 3 target_class_data_num= 100\n",
      "reduce_one_class_number target_class= 3 target_class_data_num= 100\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000,  100, 1000, 1000, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1001,  100, 1000, 1000, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000,  100, 1000, 1000, 1000, 1000, 1000]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 95.49it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 136.99it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/pyth ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "limit_and_set_train_data limit_number= 1000\n",
      "reduce_one_class_number target_class= 3 target_class_data_num= 100\n",
      "reduce_one_class_number target_class= 3 target_class_data_num= 100\n",
      "reduce_one_class_number target_class= 3 target_class_data_num= 100\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000,  100, 1000, 1000, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1001,  100, 1000, 1000, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000,  100, 1000, 1000, 1000, 1000, 1000]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 149.45it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 140.35it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/pyth ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "limit_and_set_train_data limit_number= 1000\n",
      "reduce_one_class_number target_class= 3 target_class_data_num= 100\n",
      "reduce_one_class_number target_class= 3 target_class_data_num= 100\n",
      "reduce_one_class_number target_class= 3 target_class_data_num= 100\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000,  100, 1000, 1000, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1001,  100, 1000, 1000, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000,  100, 1000, 1000, 1000, 1000, 1000]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 147.10it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 142.54it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/pyth ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "limit_and_set_train_data limit_number= 1000\n",
      "reduce_one_class_number target_class= 3 target_class_data_num= 100\n",
      "reduce_one_class_number target_class= 3 target_class_data_num= 100\n",
      "reduce_one_class_number target_class= 3 target_class_data_num= 100\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000,  100, 1000, 1000, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1001,  100, 1000, 1000, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000,  100, 1000, 1000, 1000, 1000, 1000]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 147.62it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 131.11it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/pyth ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "limit_and_set_train_data limit_number= 1000\n",
      "reduce_one_class_number target_class= 3 target_class_data_num= 100\n",
      "reduce_one_class_number target_class= 3 target_class_data_num= 100\n",
      "reduce_one_class_number target_class= 3 target_class_data_num= 100\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000,  100, 1000, 1000, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1001,  100, 1000, 1000, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000,  100, 1000, 1000, 1000, 1000, 1000]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 147.25it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 126.11it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/pyth ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "limit_and_set_train_data limit_number= 1000\n",
      "reduce_one_class_number target_class= 3 target_class_data_num= 100\n",
      "reduce_one_class_number target_class= 3 target_class_data_num= 100\n",
      "reduce_one_class_number target_class= 3 target_class_data_num= 100\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000,  100, 1000, 1000, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1001,  100, 1000, 1000, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000,  100, 1000, 1000, 1000, 1000, 1000]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 141.72it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 181.71it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/pyth ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "limit_and_set_train_data limit_number= 1000\n",
      "reduce_one_class_number target_class= 4 target_class_data_num= 10\n",
      "reduce_one_class_number target_class= 4 target_class_data_num= 10\n",
      "reduce_one_class_number target_class= 4 target_class_data_num= 10\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000, 1000,   10, 1000, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1001,  869,   10, 1000, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000,  869,   10, 1000, 1000, 1000, 1000]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 125.60it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 115.55it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/pyth ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "limit_and_set_train_data limit_number= 1000\n",
      "reduce_one_class_number target_class= 4 target_class_data_num= 10\n",
      "reduce_one_class_number target_class= 4 target_class_data_num= 10\n",
      "reduce_one_class_number target_class= 4 target_class_data_num= 10\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000, 1000,   10, 1000, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1001,  869,   10, 1000, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000,  869,   10, 1000, 1000, 1000, 1000]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 123.83it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 135.09it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/pyth ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "limit_and_set_train_data limit_number= 1000\n",
      "reduce_one_class_number target_class= 4 target_class_data_num= 10\n",
      "reduce_one_class_number target_class= 4 target_class_data_num= 10\n",
      "reduce_one_class_number target_class= 4 target_class_data_num= 10\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000, 1000,   10, 1000, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1001,  869,   10, 1000, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000,  869,   10, 1000, 1000, 1000, 1000]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 103.39it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 162.31it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/pyth ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "limit_and_set_train_data limit_number= 1000\n",
      "reduce_one_class_number target_class= 4 target_class_data_num= 10\n",
      "reduce_one_class_number target_class= 4 target_class_data_num= 10\n",
      "reduce_one_class_number target_class= 4 target_class_data_num= 10\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000, 1000,   10, 1000, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1001,  869,   10, 1000, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000,  869,   10, 1000, 1000, 1000, 1000]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 155.40it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 189.87it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/pyth ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "limit_and_set_train_data limit_number= 1000\n",
      "reduce_one_class_number target_class= 4 target_class_data_num= 10\n",
      "reduce_one_class_number target_class= 4 target_class_data_num= 10\n",
      "reduce_one_class_number target_class= 4 target_class_data_num= 10\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000, 1000,   10, 1000, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1001,  869,   10, 1000, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000,  869,   10, 1000, 1000, 1000, 1000]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 159.29it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 177.41it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/pyth ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "limit_and_set_train_data limit_number= 1000\n",
      "reduce_one_class_number target_class= 4 target_class_data_num= 10\n",
      "reduce_one_class_number target_class= 4 target_class_data_num= 10\n",
      "reduce_one_class_number target_class= 4 target_class_data_num= 10\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000, 1000,   10, 1000, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1001,  869,   10, 1000, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000,  869,   10, 1000, 1000, 1000, 1000]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 114.19it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 138.69it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/pyth ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "limit_and_set_train_data limit_number= 1000\n",
      "reduce_one_class_number target_class= 4 target_class_data_num= 20\n",
      "reduce_one_class_number target_class= 4 target_class_data_num= 20\n",
      "reduce_one_class_number target_class= 4 target_class_data_num= 20\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000, 1000,   20, 1000, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1001,  869,   20, 1000, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000,  869,   20, 1000, 1000, 1000, 1000]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 148.18it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 176.58it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/pyth ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "limit_and_set_train_data limit_number= 1000\n",
      "reduce_one_class_number target_class= 4 target_class_data_num= 20\n",
      "reduce_one_class_number target_class= 4 target_class_data_num= 20\n",
      "reduce_one_class_number target_class= 4 target_class_data_num= 20\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000, 1000,   20, 1000, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1001,  869,   20, 1000, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000,  869,   20, 1000, 1000, 1000, 1000]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 109.65it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 184.60it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/pyth ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "limit_and_set_train_data limit_number= 1000\n",
      "reduce_one_class_number target_class= 4 target_class_data_num= 20\n",
      "reduce_one_class_number target_class= 4 target_class_data_num= 20\n",
      "reduce_one_class_number target_class= 4 target_class_data_num= 20\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000, 1000,   20, 1000, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1001,  869,   20, 1000, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000,  869,   20, 1000, 1000, 1000, 1000]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 145.31it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 142.97it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/pyth ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "limit_and_set_train_data limit_number= 1000\n",
      "reduce_one_class_number target_class= 4 target_class_data_num= 20\n",
      "reduce_one_class_number target_class= 4 target_class_data_num= 20\n",
      "reduce_one_class_number target_class= 4 target_class_data_num= 20\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000, 1000,   20, 1000, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1001,  869,   20, 1000, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000,  869,   20, 1000, 1000, 1000, 1000]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 102.10it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 165.86it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/pyth ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "limit_and_set_train_data limit_number= 1000\n",
      "reduce_one_class_number target_class= 4 target_class_data_num= 20\n",
      "reduce_one_class_number target_class= 4 target_class_data_num= 20\n",
      "reduce_one_class_number target_class= 4 target_class_data_num= 20\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000, 1000,   20, 1000, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1001,  869,   20, 1000, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000,  869,   20, 1000, 1000, 1000, 1000]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 149.96it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 177.75it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/pyth ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "limit_and_set_train_data limit_number= 1000\n",
      "reduce_one_class_number target_class= 4 target_class_data_num= 20\n",
      "reduce_one_class_number target_class= 4 target_class_data_num= 20\n",
      "reduce_one_class_number target_class= 4 target_class_data_num= 20\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000, 1000,   20, 1000, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1001,  869,   20, 1000, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000,  869,   20, 1000, 1000, 1000, 1000]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 148.82it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 172.55it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/pyth ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "limit_and_set_train_data limit_number= 1000\n",
      "reduce_one_class_number target_class= 4 target_class_data_num= 30\n",
      "reduce_one_class_number target_class= 4 target_class_data_num= 30\n",
      "reduce_one_class_number target_class= 4 target_class_data_num= 30\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000, 1000,   30, 1000, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1001,  869,   30, 1000, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000,  869,   30, 1000, 1000, 1000, 1000]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 155.02it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 147.02it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/pyth ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "limit_and_set_train_data limit_number= 1000\n",
      "reduce_one_class_number target_class= 4 target_class_data_num= 30\n",
      "reduce_one_class_number target_class= 4 target_class_data_num= 30\n",
      "reduce_one_class_number target_class= 4 target_class_data_num= 30\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000, 1000,   30, 1000, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1001,  869,   30, 1000, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000,  869,   30, 1000, 1000, 1000, 1000]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 118.09it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 144.89it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/pyth ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "limit_and_set_train_data limit_number= 1000\n",
      "reduce_one_class_number target_class= 4 target_class_data_num= 30\n",
      "reduce_one_class_number target_class= 4 target_class_data_num= 30\n",
      "reduce_one_class_number target_class= 4 target_class_data_num= 30\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000, 1000,   30, 1000, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1001,  869,   30, 1000, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000,  869,   30, 1000, 1000, 1000, 1000]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 110.26it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 180.96it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/pyth ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "limit_and_set_train_data limit_number= 1000\n",
      "reduce_one_class_number target_class= 4 target_class_data_num= 30\n",
      "reduce_one_class_number target_class= 4 target_class_data_num= 30\n",
      "reduce_one_class_number target_class= 4 target_class_data_num= 30\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000, 1000,   30, 1000, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1001,  869,   30, 1000, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000,  869,   30, 1000, 1000, 1000, 1000]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 106.71it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 165.26it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/pyth ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "limit_and_set_train_data limit_number= 1000\n",
      "reduce_one_class_number target_class= 4 target_class_data_num= 30\n",
      "reduce_one_class_number target_class= 4 target_class_data_num= 30\n",
      "reduce_one_class_number target_class= 4 target_class_data_num= 30\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000, 1000,   30, 1000, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1001,  869,   30, 1000, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000,  869,   30, 1000, 1000, 1000, 1000]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 111.63it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 141.94it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/pyth ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "limit_and_set_train_data limit_number= 1000\n",
      "reduce_one_class_number target_class= 4 target_class_data_num= 30\n",
      "reduce_one_class_number target_class= 4 target_class_data_num= 30\n",
      "reduce_one_class_number target_class= 4 target_class_data_num= 30\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000, 1000,   30, 1000, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1001,  869,   30, 1000, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000,  869,   30, 1000, 1000, 1000, 1000]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 157.18it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 182.74it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/pyth ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "limit_and_set_train_data limit_number= 1000\n",
      "reduce_one_class_number target_class= 4 target_class_data_num= 50\n",
      "reduce_one_class_number target_class= 4 target_class_data_num= 50\n",
      "reduce_one_class_number target_class= 4 target_class_data_num= 50\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000, 1000,   50, 1000, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1001,  869,   50, 1000, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000,  869,   50, 1000, 1000, 1000, 1000]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 107.78it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 181.51it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/pyth ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "limit_and_set_train_data limit_number= 1000\n",
      "reduce_one_class_number target_class= 4 target_class_data_num= 50\n",
      "reduce_one_class_number target_class= 4 target_class_data_num= 50\n",
      "reduce_one_class_number target_class= 4 target_class_data_num= 50\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000, 1000,   50, 1000, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1001,  869,   50, 1000, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000,  869,   50, 1000, 1000, 1000, 1000]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 131.16it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 143.67it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/pyth ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "limit_and_set_train_data limit_number= 1000\n",
      "reduce_one_class_number target_class= 4 target_class_data_num= 50\n",
      "reduce_one_class_number target_class= 4 target_class_data_num= 50\n",
      "reduce_one_class_number target_class= 4 target_class_data_num= 50\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000, 1000,   50, 1000, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1001,  869,   50, 1000, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000,  869,   50, 1000, 1000, 1000, 1000]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 149.75it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 139.20it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/pyth ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "limit_and_set_train_data limit_number= 1000\n",
      "reduce_one_class_number target_class= 4 target_class_data_num= 50\n",
      "reduce_one_class_number target_class= 4 target_class_data_num= 50\n",
      "reduce_one_class_number target_class= 4 target_class_data_num= 50\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000, 1000,   50, 1000, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1001,  869,   50, 1000, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000,  869,   50, 1000, 1000, 1000, 1000]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 86.19it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 117.27it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/pyth ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "limit_and_set_train_data limit_number= 1000\n",
      "reduce_one_class_number target_class= 4 target_class_data_num= 50\n",
      "reduce_one_class_number target_class= 4 target_class_data_num= 50\n",
      "reduce_one_class_number target_class= 4 target_class_data_num= 50\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000, 1000,   50, 1000, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1001,  869,   50, 1000, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000,  869,   50, 1000, 1000, 1000, 1000]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 146.53it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 171.06it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/pyth ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "limit_and_set_train_data limit_number= 1000\n",
      "reduce_one_class_number target_class= 4 target_class_data_num= 50\n",
      "reduce_one_class_number target_class= 4 target_class_data_num= 50\n",
      "reduce_one_class_number target_class= 4 target_class_data_num= 50\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000, 1000,   50, 1000, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1001,  869,   50, 1000, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000,  869,   50, 1000, 1000, 1000, 1000]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 103.13it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 126.48it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/pyth ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "limit_and_set_train_data limit_number= 1000\n",
      "reduce_one_class_number target_class= 4 target_class_data_num= 100\n",
      "reduce_one_class_number target_class= 4 target_class_data_num= 100\n",
      "reduce_one_class_number target_class= 4 target_class_data_num= 100\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000, 1000,  100, 1000, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1001,  869,  100, 1000, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000,  869,  100, 1000, 1000, 1000, 1000]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 110.44it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 182.65it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/pyth ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "limit_and_set_train_data limit_number= 1000\n",
      "reduce_one_class_number target_class= 4 target_class_data_num= 100\n",
      "reduce_one_class_number target_class= 4 target_class_data_num= 100\n",
      "reduce_one_class_number target_class= 4 target_class_data_num= 100\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000, 1000,  100, 1000, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1001,  869,  100, 1000, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000,  869,  100, 1000, 1000, 1000, 1000]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 114.30it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 171.82it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/pyth ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "limit_and_set_train_data limit_number= 1000\n",
      "reduce_one_class_number target_class= 4 target_class_data_num= 100\n",
      "reduce_one_class_number target_class= 4 target_class_data_num= 100\n",
      "reduce_one_class_number target_class= 4 target_class_data_num= 100\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000, 1000,  100, 1000, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1001,  869,  100, 1000, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000,  869,  100, 1000, 1000, 1000, 1000]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 105.28it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 142.07it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/pyth ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "limit_and_set_train_data limit_number= 1000\n",
      "reduce_one_class_number target_class= 4 target_class_data_num= 100\n",
      "reduce_one_class_number target_class= 4 target_class_data_num= 100\n",
      "reduce_one_class_number target_class= 4 target_class_data_num= 100\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000, 1000,  100, 1000, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1001,  869,  100, 1000, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000,  869,  100, 1000, 1000, 1000, 1000]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 140.50it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 165.50it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/pyth ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "limit_and_set_train_data limit_number= 1000\n",
      "reduce_one_class_number target_class= 4 target_class_data_num= 100\n",
      "reduce_one_class_number target_class= 4 target_class_data_num= 100\n",
      "reduce_one_class_number target_class= 4 target_class_data_num= 100\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000, 1000,  100, 1000, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1001,  869,  100, 1000, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000,  869,  100, 1000, 1000, 1000, 1000]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 112.09it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 191.39it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/pyth ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "limit_and_set_train_data limit_number= 1000\n",
      "reduce_one_class_number target_class= 4 target_class_data_num= 100\n",
      "reduce_one_class_number target_class= 4 target_class_data_num= 100\n",
      "reduce_one_class_number target_class= 4 target_class_data_num= 100\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000, 1000,  100, 1000, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1001,  869,  100, 1000, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000,  869,  100, 1000, 1000, 1000, 1000]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 162.23it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 191.18it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/pyth ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "limit_and_set_train_data limit_number= 1000\n",
      "reduce_one_class_number target_class= 5 target_class_data_num= 10\n",
      "reduce_one_class_number target_class= 5 target_class_data_num= 10\n",
      "reduce_one_class_number target_class= 5 target_class_data_num= 10\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000, 1000, 1000,   10, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1001,  869, 1000,   10, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000,  869, 1000,   10, 1000, 1000, 1000]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 127.41it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 133.14it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/pyth ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "limit_and_set_train_data limit_number= 1000\n",
      "reduce_one_class_number target_class= 5 target_class_data_num= 10\n",
      "reduce_one_class_number target_class= 5 target_class_data_num= 10\n",
      "reduce_one_class_number target_class= 5 target_class_data_num= 10\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000, 1000, 1000,   10, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1001,  869, 1000,   10, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000,  869, 1000,   10, 1000, 1000, 1000]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 102.06it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 135.55it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/pyth ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "limit_and_set_train_data limit_number= 1000\n",
      "reduce_one_class_number target_class= 5 target_class_data_num= 10\n",
      "reduce_one_class_number target_class= 5 target_class_data_num= 10\n",
      "reduce_one_class_number target_class= 5 target_class_data_num= 10\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000, 1000, 1000,   10, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1001,  869, 1000,   10, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000,  869, 1000,   10, 1000, 1000, 1000]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 150.63it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 110.05it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/pyth ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "limit_and_set_train_data limit_number= 1000\n",
      "reduce_one_class_number target_class= 5 target_class_data_num= 10\n",
      "reduce_one_class_number target_class= 5 target_class_data_num= 10\n",
      "reduce_one_class_number target_class= 5 target_class_data_num= 10\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000, 1000, 1000,   10, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1001,  869, 1000,   10, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000,  869, 1000,   10, 1000, 1000, 1000]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 108.81it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 173.53it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/pyth ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "limit_and_set_train_data limit_number= 1000\n",
      "reduce_one_class_number target_class= 5 target_class_data_num= 10\n",
      "reduce_one_class_number target_class= 5 target_class_data_num= 10\n",
      "reduce_one_class_number target_class= 5 target_class_data_num= 10\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000, 1000, 1000,   10, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1001,  869, 1000,   10, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000,  869, 1000,   10, 1000, 1000, 1000]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 146.54it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 131.86it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/pyth ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "limit_and_set_train_data limit_number= 1000\n",
      "reduce_one_class_number target_class= 5 target_class_data_num= 10\n",
      "reduce_one_class_number target_class= 5 target_class_data_num= 10\n",
      "reduce_one_class_number target_class= 5 target_class_data_num= 10\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000, 1000, 1000,   10, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1001,  869, 1000,   10, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000,  869, 1000,   10, 1000, 1000, 1000]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 130.50it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 177.12it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/pyth ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "limit_and_set_train_data limit_number= 1000\n",
      "reduce_one_class_number target_class= 5 target_class_data_num= 20\n",
      "reduce_one_class_number target_class= 5 target_class_data_num= 20\n",
      "reduce_one_class_number target_class= 5 target_class_data_num= 20\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000, 1000, 1000,   20, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1001,  869, 1000,   20, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000,  869, 1000,   20, 1000, 1000, 1000]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 90.06it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 167.13it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/pyth ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "limit_and_set_train_data limit_number= 1000\n",
      "reduce_one_class_number target_class= 5 target_class_data_num= 20\n",
      "reduce_one_class_number target_class= 5 target_class_data_num= 20\n",
      "reduce_one_class_number target_class= 5 target_class_data_num= 20\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000, 1000, 1000,   20, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1001,  869, 1000,   20, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000,  869, 1000,   20, 1000, 1000, 1000]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 127.23it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 139.28it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/pyth ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "limit_and_set_train_data limit_number= 1000\n",
      "reduce_one_class_number target_class= 5 target_class_data_num= 20\n",
      "reduce_one_class_number target_class= 5 target_class_data_num= 20\n",
      "reduce_one_class_number target_class= 5 target_class_data_num= 20\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000, 1000, 1000,   20, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1001,  869, 1000,   20, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000,  869, 1000,   20, 1000, 1000, 1000]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 145.13it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 135.02it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/pyth ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "limit_and_set_train_data limit_number= 1000\n",
      "reduce_one_class_number target_class= 5 target_class_data_num= 20\n",
      "reduce_one_class_number target_class= 5 target_class_data_num= 20\n",
      "reduce_one_class_number target_class= 5 target_class_data_num= 20\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000, 1000, 1000,   20, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1001,  869, 1000,   20, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000,  869, 1000,   20, 1000, 1000, 1000]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 138.21it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 159.53it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/pyth ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "limit_and_set_train_data limit_number= 1000\n",
      "reduce_one_class_number target_class= 5 target_class_data_num= 20\n",
      "reduce_one_class_number target_class= 5 target_class_data_num= 20\n",
      "reduce_one_class_number target_class= 5 target_class_data_num= 20\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000, 1000, 1000,   20, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1001,  869, 1000,   20, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000,  869, 1000,   20, 1000, 1000, 1000]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 146.38it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 128.06it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/pyth ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "limit_and_set_train_data limit_number= 1000\n",
      "reduce_one_class_number target_class= 5 target_class_data_num= 20\n",
      "reduce_one_class_number target_class= 5 target_class_data_num= 20\n",
      "reduce_one_class_number target_class= 5 target_class_data_num= 20\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000, 1000, 1000,   20, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1001,  869, 1000,   20, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000,  869, 1000,   20, 1000, 1000, 1000]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 105.81it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 185.28it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/pyth ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "limit_and_set_train_data limit_number= 1000\n",
      "reduce_one_class_number target_class= 5 target_class_data_num= 30\n",
      "reduce_one_class_number target_class= 5 target_class_data_num= 30\n",
      "reduce_one_class_number target_class= 5 target_class_data_num= 30\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000, 1000, 1000,   30, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1001,  869, 1000,   30, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000,  869, 1000,   30, 1000, 1000, 1000]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 119.07it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 157.96it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/pyth ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "limit_and_set_train_data limit_number= 1000\n",
      "reduce_one_class_number target_class= 5 target_class_data_num= 30\n",
      "reduce_one_class_number target_class= 5 target_class_data_num= 30\n",
      "reduce_one_class_number target_class= 5 target_class_data_num= 30\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000, 1000, 1000,   30, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1001,  869, 1000,   30, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000,  869, 1000,   30, 1000, 1000, 1000]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 148.70it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 191.12it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/pyth ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "limit_and_set_train_data limit_number= 1000\n",
      "reduce_one_class_number target_class= 5 target_class_data_num= 30\n",
      "reduce_one_class_number target_class= 5 target_class_data_num= 30\n",
      "reduce_one_class_number target_class= 5 target_class_data_num= 30\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000, 1000, 1000,   30, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1001,  869, 1000,   30, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000,  869, 1000,   30, 1000, 1000, 1000]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 143.30it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 174.19it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/pyth ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "limit_and_set_train_data limit_number= 1000\n",
      "reduce_one_class_number target_class= 5 target_class_data_num= 30\n",
      "reduce_one_class_number target_class= 5 target_class_data_num= 30\n",
      "reduce_one_class_number target_class= 5 target_class_data_num= 30\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000, 1000, 1000,   30, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1001,  869, 1000,   30, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000,  869, 1000,   30, 1000, 1000, 1000]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 158.93it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 140.12it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/pyth ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "limit_and_set_train_data limit_number= 1000\n",
      "reduce_one_class_number target_class= 5 target_class_data_num= 30\n",
      "reduce_one_class_number target_class= 5 target_class_data_num= 30\n",
      "reduce_one_class_number target_class= 5 target_class_data_num= 30\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000, 1000, 1000,   30, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1001,  869, 1000,   30, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000,  869, 1000,   30, 1000, 1000, 1000]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 142.95it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 144.51it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/pyth ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "limit_and_set_train_data limit_number= 1000\n",
      "reduce_one_class_number target_class= 5 target_class_data_num= 30\n",
      "reduce_one_class_number target_class= 5 target_class_data_num= 30\n",
      "reduce_one_class_number target_class= 5 target_class_data_num= 30\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000, 1000, 1000,   30, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1001,  869, 1000,   30, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000,  869, 1000,   30, 1000, 1000, 1000]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 148.81it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 189.57it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/pyth ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "limit_and_set_train_data limit_number= 1000\n",
      "reduce_one_class_number target_class= 5 target_class_data_num= 50\n",
      "reduce_one_class_number target_class= 5 target_class_data_num= 50\n",
      "reduce_one_class_number target_class= 5 target_class_data_num= 50\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000, 1000, 1000,   50, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1001,  869, 1000,   50, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000,  869, 1000,   50, 1000, 1000, 1000]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 115.88it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 171.32it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/pyth ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "limit_and_set_train_data limit_number= 1000\n",
      "reduce_one_class_number target_class= 5 target_class_data_num= 50\n",
      "reduce_one_class_number target_class= 5 target_class_data_num= 50\n",
      "reduce_one_class_number target_class= 5 target_class_data_num= 50\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000, 1000, 1000,   50, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1001,  869, 1000,   50, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000,  869, 1000,   50, 1000, 1000, 1000]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 112.08it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 154.31it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/pyth ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "limit_and_set_train_data limit_number= 1000\n",
      "reduce_one_class_number target_class= 5 target_class_data_num= 50\n",
      "reduce_one_class_number target_class= 5 target_class_data_num= 50\n",
      "reduce_one_class_number target_class= 5 target_class_data_num= 50\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000, 1000, 1000,   50, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1001,  869, 1000,   50, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000,  869, 1000,   50, 1000, 1000, 1000]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 142.06it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 187.71it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/pyth ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "limit_and_set_train_data limit_number= 1000\n",
      "reduce_one_class_number target_class= 5 target_class_data_num= 50\n",
      "reduce_one_class_number target_class= 5 target_class_data_num= 50\n",
      "reduce_one_class_number target_class= 5 target_class_data_num= 50\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000, 1000, 1000,   50, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1001,  869, 1000,   50, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000,  869, 1000,   50, 1000, 1000, 1000]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 113.26it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 186.22it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/pyth ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "limit_and_set_train_data limit_number= 1000\n",
      "reduce_one_class_number target_class= 5 target_class_data_num= 50\n",
      "reduce_one_class_number target_class= 5 target_class_data_num= 50\n",
      "reduce_one_class_number target_class= 5 target_class_data_num= 50\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000, 1000, 1000,   50, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1001,  869, 1000,   50, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000,  869, 1000,   50, 1000, 1000, 1000]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 112.77it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 155.24it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/pyth ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "limit_and_set_train_data limit_number= 1000\n",
      "reduce_one_class_number target_class= 5 target_class_data_num= 50\n",
      "reduce_one_class_number target_class= 5 target_class_data_num= 50\n",
      "reduce_one_class_number target_class= 5 target_class_data_num= 50\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000, 1000, 1000,   50, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1001,  869, 1000,   50, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000,  869, 1000,   50, 1000, 1000, 1000]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 112.24it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 172.10it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/pyth ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "limit_and_set_train_data limit_number= 1000\n",
      "reduce_one_class_number target_class= 5 target_class_data_num= 100\n",
      "reduce_one_class_number target_class= 5 target_class_data_num= 100\n",
      "reduce_one_class_number target_class= 5 target_class_data_num= 100\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000, 1000, 1000,  100, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1001,  869, 1000,  100, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000,  869, 1000,  100, 1000, 1000, 1000]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 98.33it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 135.09it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/pyth ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "limit_and_set_train_data limit_number= 1000\n",
      "reduce_one_class_number target_class= 5 target_class_data_num= 100\n",
      "reduce_one_class_number target_class= 5 target_class_data_num= 100\n",
      "reduce_one_class_number target_class= 5 target_class_data_num= 100\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000, 1000, 1000,  100, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1001,  869, 1000,  100, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000,  869, 1000,  100, 1000, 1000, 1000]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 143.42it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 141.15it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/pyth ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "limit_and_set_train_data limit_number= 1000\n",
      "reduce_one_class_number target_class= 5 target_class_data_num= 100\n",
      "reduce_one_class_number target_class= 5 target_class_data_num= 100\n",
      "reduce_one_class_number target_class= 5 target_class_data_num= 100\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000, 1000, 1000,  100, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1001,  869, 1000,  100, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000,  869, 1000,  100, 1000, 1000, 1000]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 148.92it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 183.23it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/pyth ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "limit_and_set_train_data limit_number= 1000\n",
      "reduce_one_class_number target_class= 5 target_class_data_num= 100\n",
      "reduce_one_class_number target_class= 5 target_class_data_num= 100\n",
      "reduce_one_class_number target_class= 5 target_class_data_num= 100\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000, 1000, 1000,  100, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1001,  869, 1000,  100, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000,  869, 1000,  100, 1000, 1000, 1000]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 141.21it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 148.33it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/pyth ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "limit_and_set_train_data limit_number= 1000\n",
      "reduce_one_class_number target_class= 5 target_class_data_num= 100\n",
      "reduce_one_class_number target_class= 5 target_class_data_num= 100\n",
      "reduce_one_class_number target_class= 5 target_class_data_num= 100\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000, 1000, 1000,  100, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1001,  869, 1000,  100, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000,  869, 1000,  100, 1000, 1000, 1000]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 144.30it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 183.87it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/pyth ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "limit_and_set_train_data limit_number= 1000\n",
      "reduce_one_class_number target_class= 5 target_class_data_num= 100\n",
      "reduce_one_class_number target_class= 5 target_class_data_num= 100\n",
      "reduce_one_class_number target_class= 5 target_class_data_num= 100\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000, 1000, 1000,  100, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1001,  869, 1000,  100, 1000, 1000, 1000]))\n",
      "(array([1., 2., 3., 4., 5., 6., 7., 8.]), array([1000, 1000,  869, 1000,  100, 1000, 1000, 1000]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 143.75it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 152.13it/s]\n"
     ]
    }
   ],
   "source": [
    "acc_result_dict = defaultdict(list)\n",
    "save_model_folder_dict = defaultdict(list)\n",
    "target_class_tpr_result_dict = defaultdict(list)\n",
    "\n",
    "for args.target_class in [3, 4, 5]:\n",
    "    for args.target_class_data_num in \"10 20 30 50 100\".split(\" \"):\n",
    "        args.target_class_data_num = int(args.target_class_data_num)\n",
    "        for args.random_seed in \"42 64\".split(\" \"):\n",
    "            for args.patience in \"200 300 400\".split(\" \"):\n",
    "                save_model_folder = log_save_name.format(args.model_name, args.class_num, args.train_limit_data, args.target_class, args.target_class_data_num, args.patience, args.random_seed)\n",
    "                print(\"RUNNING FOR\", save_model_folder)\n",
    "                test_acc, target_class_tpr = get_acc_from_save_folder(save_model_folder)\n",
    "                print(\"test_acc, target_class_tpr\", test_acc, target_class_tpr)\n",
    "                # test_acc = random.random()\n",
    "                acc_result_dict[(args.target_class, args.target_class_data_num)].append(test_acc.item())\n",
    "                save_model_folder_dict[(args.target_class, args.target_class_data_num)].append(save_model_folder)\n",
    "                target_class_tpr_result_dict[(args.target_class, args.target_class_data_num)].append(target_class_tpr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20_AL_train_unbalance/4cnn_64-8-1000-3-10-300-64 20_AL_train_unbalance/4cnn_64-8-1000-3-20-300-42 20_AL_train_unbalance/4cnn_64-8-1000-3-30-400-64 20_AL_train_unbalance/4cnn_64-8-1000-3-50-200-64 20_AL_train_unbalance/4cnn_64-8-1000-3-100-400-42 20_AL_train_unbalance/4cnn_64-8-1000-4-10-400-64 20_AL_train_unbalance/4cnn_64-8-1000-4-20-300-64 20_AL_train_unbalance/4cnn_64-8-1000-4-30-200-64 20_AL_train_unbalance/4cnn_64-8-1000-4-50-400-42 20_AL_train_unbalance/4cnn_64-8-1000-4-100-300-64 20_AL_train_unbalance/4cnn_64-8-1000-5-10-400-64 20_AL_train_unbalance/4cnn_64-8-1000-5-20-200-42 20_AL_train_unbalance/4cnn_64-8-1000-5-30-300-64 20_AL_train_unbalance/4cnn_64-8-1000-5-50-400-42 20_AL_train_unbalance/4cnn_64-8-1000-5-100-300-64 "
     ]
    }
   ],
   "source": [
    "for args.target_class in [3, 4, 5]:\n",
    "    for args.target_class_data_num in \"10 20 30 50 100\".split(\" \"):\n",
    "        args.target_class_data_num = int(args.target_class_data_num)\n",
    "        \n",
    "        print(\"save_model_folder_dict\", save_model_folder_dict[(args.target_class, args.target_class_data_num)])\n",
    "        print(\"acc_result_dict\", acc_result_dict[(args.target_class, args.target_class_data_num)])\n",
    "        print(\"target_class_tpr_result_dict\", target_class_tpr_result_dict[(args.target_class, args.target_class_data_num)])\n",
    "\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for args.target_class in [3, 4, 5]:\n",
    "    for args.target_class_data_num in \"10 20 30 50 100\".split(\" \"):\n",
    "        args.target_class_data_num = int(args.target_class_data_num)\n",
    "        \n",
    "        argmax_idx = np.argmax(acc_result_dict[(args.target_class, args.target_class_data_num)])\n",
    "        print(save_model_folder_dict[(args.target_class, args.target_class_data_num)][argmax_idx], end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# a = [\n",
    "#     [\n",
    "#             ['20_AL_train_unbalance/4cnn_64-8-1000-3-10-200-42', '20_AL_train_unbalance/4cnn_64-8-1000-3-10-300-42', '20_AL_train_unbalance/4cnn_64-8-1000-3-10-400-42', '20_AL_train_unbalance/4cnn_64-8-1000-3-10-200-64', '20_AL_train_unbalance/4cnn_64-8-1000-3-10-300-64', '20_AL_train_unbalance/4cnn_64-8-1000-3-10-400-64'],\n",
    "#             [0.7486447691917419, 0.7734664678573608, 0.766333818435669, 0.7821683287620544, 0.7884450554847717, 0.7771754860877991],\n",
    "#             [0.9, 0.8, 0.9, 1.0, 0.8, 0.9]],\n",
    "#     [\n",
    "#             ['20_AL_train_unbalance/4cnn_64-8-1000-3-20-200-42', '20_AL_train_unbalance/4cnn_64-8-1000-3-20-300-42', '20_AL_train_unbalance/4cnn_64-8-1000-3-20-400-42', '20_AL_train_unbalance/4cnn_64-8-1000-3-20-200-64', '20_AL_train_unbalance/4cnn_64-8-1000-3-20-300-64', '20_AL_train_unbalance/4cnn_64-8-1000-3-20-400-64'],\n",
    "#             [0.7565526962280273, 0.7754985690116882, 0.7270655035972595, 0.7118233442306519, 0.7058404684066772, 0.7289173603057861],\n",
    "#             [0.85, 0.95, 0.85, 1.0, 0.9, 1.0]],\n",
    "#     [\n",
    "#             ['20_AL_train_unbalance/4cnn_64-8-1000-3-30-200-42', '20_AL_train_unbalance/4cnn_64-8-1000-3-30-300-42', '20_AL_train_unbalance/4cnn_64-8-1000-3-30-400-42', '20_AL_train_unbalance/4cnn_64-8-1000-3-30-200-64', '20_AL_train_unbalance/4cnn_64-8-1000-3-30-300-64', '20_AL_train_unbalance/4cnn_64-8-1000-3-30-400-64'],\n",
    "#             [0.7123755216598511, 0.7443812489509583, 0.6816500425338745, 0.7492176294326782, 0.695732593536377, 0.7520625591278076],\n",
    "#             [0.8333333333333334, 1.0, 0.8333333333333334, 0.9333333333333333, 0.9, 0.9666666666666667]],\n",
    "#     [\n",
    "#             ['20_AL_train_unbalance/4cnn_64-8-1000-3-50-200-42', '20_AL_train_unbalance/4cnn_64-8-1000-3-50-300-42', '20_AL_train_unbalance/4cnn_64-8-1000-3-50-400-42', '20_AL_train_unbalance/4cnn_64-8-1000-3-50-200-64', '20_AL_train_unbalance/4cnn_64-8-1000-3-50-300-64', '20_AL_train_unbalance/4cnn_64-8-1000-3-50-400-64'],\n",
    "#             [0.7825531959533691, 0.7832624316215515, 0.7178723216056824, 0.7937588691711426, 0.778723418712616, 0.7797163128852844],\n",
    "#             [0.98, 0.98, 0.98, 1.0, 0.98, 1.0]],\n",
    "#     [\n",
    "#             ['20_AL_train_unbalance/4cnn_64-8-1000-3-100-200-42', '20_AL_train_unbalance/4cnn_64-8-1000-3-100-300-42', '20_AL_train_unbalance/4cnn_64-8-1000-3-100-400-42', '20_AL_train_unbalance/4cnn_64-8-1000-3-100-200-64', '20_AL_train_unbalance/4cnn_64-8-1000-3-100-300-64', '20_AL_train_unbalance/4cnn_64-8-1000-3-100-400-64'],\n",
    "#             [0.7722535133361816, 0.6798591613769531, 0.8038027882575989, 0.7366197109222412, 0.7081690430641174, 0.7018309831619263],\n",
    "#             [0.99, 1.0, 0.99, 1.0, 0.99, 1.0]],\n",
    "#     [\n",
    "#             ['20_AL_train_unbalance/4cnn_64-8-1000-4-10-200-42', '20_AL_train_unbalance/4cnn_64-8-1000-4-10-300-42', '20_AL_train_unbalance/4cnn_64-8-1000-4-10-400-42', '20_AL_train_unbalance/4cnn_64-8-1000-4-10-200-64', '20_AL_train_unbalance/4cnn_64-8-1000-4-10-300-64', '20_AL_train_unbalance/4cnn_64-8-1000-4-10-400-64'],\n",
    "#             [0.6378834247589111, 0.7386248111724854, 0.709114670753479, 0.7554877400398254, 0.7338275909423828, 0.7601395845413208],\n",
    "#             [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]],\n",
    "#     [\n",
    "#             ['20_AL_train_unbalance/4cnn_64-8-1000-4-20-200-42', '20_AL_train_unbalance/4cnn_64-8-1000-4-20-300-42', '20_AL_train_unbalance/4cnn_64-8-1000-4-20-400-42', '20_AL_train_unbalance/4cnn_64-8-1000-4-20-200-64', '20_AL_train_unbalance/4cnn_64-8-1000-4-20-300-64', '20_AL_train_unbalance/4cnn_64-8-1000-4-20-400-64'],\n",
    "#             [0.7747133374214172, 0.7583103775978088, 0.7686166167259216, 0.7745681405067444, 0.7998257875442505, 0.7300043702125549],\n",
    "#             [0.0, 0.0, 0.45, 0.0, 0.1, 0.0]],\n",
    "#     [\n",
    "#             ['20_AL_train_unbalance/4cnn_64-8-1000-4-30-200-42', '20_AL_train_unbalance/4cnn_64-8-1000-4-30-300-42', '20_AL_train_unbalance/4cnn_64-8-1000-4-30-400-42', '20_AL_train_unbalance/4cnn_64-8-1000-4-30-200-64', '20_AL_train_unbalance/4cnn_64-8-1000-4-30-300-64', '20_AL_train_unbalance/4cnn_64-8-1000-4-30-400-64'],\n",
    "#             [0.699811577796936, 0.7506884932518005, 0.7270618677139282, 0.7835918068885803, 0.6967676281929016, 0.6921293139457703],\n",
    "#             [0.4666666666666667, 0.03333333333333333, 0.06666666666666667, 0.0, 0.03333333333333333, 0.0]],\n",
    "#     [\n",
    "#             ['20_AL_train_unbalance/4cnn_64-8-1000-4-50-200-42', '20_AL_train_unbalance/4cnn_64-8-1000-4-50-300-42', '20_AL_train_unbalance/4cnn_64-8-1000-4-50-400-42', '20_AL_train_unbalance/4cnn_64-8-1000-4-50-200-64', '20_AL_train_unbalance/4cnn_64-8-1000-4-50-300-64', '20_AL_train_unbalance/4cnn_64-8-1000-4-50-400-64'],\n",
    "#             [0.7397022843360901, 0.7660066485404968, 0.7837837934494019, 0.7375343441963196, 0.7376788258552551, 0.6203208565711975],\n",
    "#             [0.58, 0.66, 0.68, 0.42, 0.74, 0.74]],\n",
    "#     [\n",
    "#             ['20_AL_train_unbalance/4cnn_64-8-1000-4-100-200-42', '20_AL_train_unbalance/4cnn_64-8-1000-4-100-300-42', '20_AL_train_unbalance/4cnn_64-8-1000-4-100-400-42', '20_AL_train_unbalance/4cnn_64-8-1000-4-100-200-64', '20_AL_train_unbalance/4cnn_64-8-1000-4-100-300-64', '20_AL_train_unbalance/4cnn_64-8-1000-4-100-400-64'],\n",
    "#             [0.732816755771637, 0.7869134545326233, 0.782608687877655, 0.7866265177726746, 0.7912182807922363, 0.7201893925666809],\n",
    "#             [0.67, 0.73, 0.72, 0.63, 0.63, 0.57]],\n",
    "#     [\n",
    "#             ['20_AL_train_unbalance/4cnn_64-8-1000-5-10-200-42', '20_AL_train_unbalance/4cnn_64-8-1000-5-10-300-42', '20_AL_train_unbalance/4cnn_64-8-1000-5-10-400-42', '20_AL_train_unbalance/4cnn_64-8-1000-5-10-200-64', '20_AL_train_unbalance/4cnn_64-8-1000-5-10-300-64', '20_AL_train_unbalance/4cnn_64-8-1000-5-10-400-64'],\n",
    "#             [0.7848524451255798, 0.7015554308891296, 0.744148850440979, 0.747056245803833, 0.7708969116210938, 0.8181421756744385],\n",
    "#             [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]],\n",
    "#     [\n",
    "#             ['20_AL_train_unbalance/4cnn_64-8-1000-5-20-200-42', '20_AL_train_unbalance/4cnn_64-8-1000-5-20-300-42', '20_AL_train_unbalance/4cnn_64-8-1000-5-20-400-42', '20_AL_train_unbalance/4cnn_64-8-1000-5-20-200-64', '20_AL_train_unbalance/4cnn_64-8-1000-5-20-300-64', '20_AL_train_unbalance/4cnn_64-8-1000-5-20-400-64'],\n",
    "#             [0.7911162972450256, 0.7446653842926025, 0.7465524673461914, 0.6922630071640015, 0.7410364151000977, 0.7813906073570251],\n",
    "#             [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]],\n",
    "#     [\n",
    "#             ['20_AL_train_unbalance/4cnn_64-8-1000-5-30-200-42', '20_AL_train_unbalance/4cnn_64-8-1000-5-30-300-42', '20_AL_train_unbalance/4cnn_64-8-1000-5-30-400-42', '20_AL_train_unbalance/4cnn_64-8-1000-5-30-200-64', '20_AL_train_unbalance/4cnn_64-8-1000-5-30-300-64', '20_AL_train_unbalance/4cnn_64-8-1000-5-30-400-64'],\n",
    "#             [0.6211044788360596, 0.8095375895500183, 0.7608349323272705, 0.8038846254348755, 0.8221481442451477, 0.7977967858314514],\n",
    "#             [0.0, 0.0, 0.0, 0.0, 0.06666666666666667, 0.06666666666666667]],\n",
    "#     [\n",
    "#             ['20_AL_train_unbalance/4cnn_64-8-1000-5-50-200-42', '20_AL_train_unbalance/4cnn_64-8-1000-5-50-300-42', '20_AL_train_unbalance/4cnn_64-8-1000-5-50-400-42', '20_AL_train_unbalance/4cnn_64-8-1000-5-50-200-64', '20_AL_train_unbalance/4cnn_64-8-1000-5-50-300-64', '20_AL_train_unbalance/4cnn_64-8-1000-5-50-400-64'],\n",
    "#             [0.744327187538147, 0.7277063131332397, 0.7986703515052795, 0.7975140810012817, 0.7671628594398499, 0.7423037886619568],\n",
    "#             [0.0, 0.0, 0.02, 0.18, 0.02, 0.32]],\n",
    "#     [\n",
    "#             ['20_AL_train_unbalance/4cnn_64-8-1000-5-100-2,00-42', '20_AL_train_unbalance/4cnn_64-8-1000-5-100-300-42', '20_AL_train_unbalance/4cnn_64-8-1000-5-100-400-42', '20_AL_train_unbalance/4cnn_64-8-1000-5-100-200-64', '20_AL_train_unbalance/4cnn_64-8-1000-5-100-300-64', '20_AL_train_unbalance/4cnn_64-8-1000-5-100-400-64'],\n",
    "#             [0.7478834986686707, 0.8028411269187927, 0.7666,810154914856, 0.7338212132453918, 0.8092983365058899, 0.7864829897880554],\n",
    "#             [0.16, 0.1, 0.59, 0.06, 0.26, 0.3]]\n",
    "# ]\n",
    "\n",
    "# acc_result_dict = defaultdict(list)\n",
    "# save_model_folder_dict = defaultdict(list)\n",
    "# target_class_tpr_result_dict = defaultdict(list)\n",
    "\n",
    "# i = 0\n",
    "# for args.target_class in [3, 4, 5]:\n",
    "#     for args.target_class_data_num in \"10 20 30 50 100\".split(\" \"):\n",
    "#         args.target_class_data_num = int(args.target_class_data_num)\n",
    "#         ai = a [i]\n",
    "#         save_model_folder_dict[(args.target_class, args.target_class_data_num)] = ai[0]\n",
    "#         acc_result_dict[(args.target_class, args.target_class_data_num)] = ai[1]\n",
    "#         target_class_tpr_result_dict[(args.target_class, args.target_class_data_num)] = ai[2]\n",
    "#         i+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.6378834247589111, 0.7386248111724854, 0.709114670753479, 0.7554877400398254, 0.7338275909423828, 0.7601395845413208], [0.7747133374214172, 0.7583103775978088, 0.7686166167259216, 0.7745681405067444, 0.7998257875442505, 0.7300043702125549], [0.699811577796936, 0.7506884932518005, 0.7270618677139282, 0.7835918068885803, 0.6967676281929016, 0.6921293139457703], [0.7397022843360901, 0.7660066485404968, 0.7837837934494019, 0.7375343441963196, 0.7376788258552551, 0.6203208565711975], [0.732816755771637, 0.7869134545326233, 0.782608687877655, 0.7866265177726746, 0.7912182807922363, 0.7201893925666809]]\n",
      "[0.72251297 0.76767311 0.72500845 0.73083779 0.76672885] [0.04129646 0.02096976 0.03318924 0.05232008 0.02878422]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_157357/3144200331.py:24: UserWarning: linestyle is redundantly defined by the 'linestyle' keyword argument and the fmt string \"-\" (-> linestyle='-'). The keyword argument will take precedence.\n",
      "  ax.errorbar(x + offset + width/2, mean, std, linestyle='None', fmt='-', color=\"black\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.axis.XTick at 0x7f4583e1dac0>,\n",
       " <matplotlib.axis.XTick at 0x7f4583e1da90>,\n",
       " <matplotlib.axis.XTick at 0x7f4583e1d5b0>,\n",
       " <matplotlib.axis.XTick at 0x7f4583e05220>,\n",
       " <matplotlib.axis.XTick at 0x7f4583de4550>]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAf8AAAGbCAYAAADKlJnyAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/OQEPoAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAr3ElEQVR4nO3de1TVdb7/8RcXuXgBFRUkFbHMNIwKzaAss8S0m11OVmsyUifJu1g5ZGU6Tnjq5CVNncbUOpkypXasoZIyL6V2EiFNSRlveIEcNQUZDyh8fn+03L/ZAyhb92aLn+djrb2W+7M/3+/3/f24Fy8+3wtfH2OMEQAAsIavtwsAAAC1i/AHAMAyhD8AAJYh/AEAsAzhDwCAZQh/AAAsQ/gDAGAZwh8AAMsQ/gAAWIbwBwDAMl4N/7Vr1+q+++5TZGSkfHx89Mknn5x3mTVr1iguLk5BQUFq166d5s6d6/lCAQC4jHg1/EtKShQbG6tZs2bVqP+ePXvUt29fde/eXdnZ2XrxxRc1cuRILV261MOVAgBw+fC5VB7s4+Pjo+XLl6tfv37V9hk3bpxWrFih3NxcR1tycrJ+/PFHbdiwoRaqBACg7vP3dgGu2LBhgxITE53aevfurXfffVenT59WvXr1Ki1TWlqq0tJSx/uKigodO3ZMYWFh8vHx8XjNAADUFmOMiouLFRkZKV/f6g/u16nwLywsVHh4uFNbeHi4zpw5oyNHjqhly5aVlklLS9PEiRNrq0QAALxu//79atWqVbWf16nwl1Rptn72rEV1s/jU1FSlpKQ43p84cUJt2rTR/v37FRIS4rlCAQCoZUVFRWrdurUaNWp0zn51KvwjIiJUWFjo1Hb48GH5+/srLCysymUCAwMVGBhYqT0kJITwBwBcls53WrtO3ecfHx+vzMxMp7aVK1eqS5cuVZ7vBwAAlXk1/E+ePKmcnBzl5ORI+u1WvpycHOXn50v67ZD9gAEDHP2Tk5O1b98+paSkKDc3V/Pnz9e7776r5557zhvlAwBQJ3n1sP+mTZt0xx13ON6fPTf/1FNPaeHChSooKHD8IiBJ0dHRysjI0JgxY/T2228rMjJSb731lh5++OFarx0AgLrqkrnPv7YUFRUpNDRUJ06c4Jw/AOCyUtOMq1Pn/AEAwMUj/AEAsAzhDwCAZQh/AAAsQ/gDAGAZwh8AAMsQ/gAAWIbwBwDAMoQ/AACWIfwBALAM4Q8AgGUIfwAALEP4AwBgGcIfAADLEP4AAFiG8AcAwDKEPwAAliH8AQCwDOEPAIBlCH8AACxD+AMAYBnCHwAAyxD+AABYhvAHAMAyhD8AAJYh/AEAsAzhDwCAZQh/AAAsQ/gDAGAZwh8AAMsQ/gAAWIbwBwDAMoQ/AACWIfwBALAM4Q8AgGUIfwAALEP4AwBgGcIfAADLEP4AAFiG8AcAwDKEPwAAliH8AQCwDOEPAIBlCH8AACxD+AMAYBnCHwAAyxD+AABYhvAHAMAyhD8AAJYh/AEAsAzhDwCAZQh/AAAsQ/gDAGAZwh8AAMsQ/gAAWIbwBwDAMoQ/AACWIfwBALCM18N/9uzZio6OVlBQkOLi4rRu3bpz9l+0aJFiY2NVv359tWzZUk8//bSOHj1aS9UCAFD3eTX809PTNXr0aI0fP17Z2dnq3r27+vTpo/z8/Cr7f/vttxowYIAGDRqkbdu26aOPPtIPP/ygwYMH13LlAADUXV4N/6lTp2rQoEEaPHiwOnbsqOnTp6t169aaM2dOlf03btyotm3bauTIkYqOjtatt96qIUOGaNOmTdVuo7S0VEVFRU4vAABs5rXwLysrU1ZWlhITE53aExMTtX79+iqXSUhI0IEDB5SRkSFjjH755Rd9/PHHuueee6rdTlpamkJDQx2v1q1bu3U/AACoa7wW/keOHFF5ebnCw8Od2sPDw1VYWFjlMgkJCVq0aJH69++vgIAARUREqHHjxpo5c2a120lNTdWJEyccr/3797t1PwAAqGu8fsGfj4+P03tjTKW2s7Zv366RI0fqlVdeUVZWlr744gvt2bNHycnJ1a4/MDBQISEhTi8AAGqipKREPj4+8vHxUUlJibfLcRt/b224WbNm8vPzqzTLP3z4cKWjAWelpaXplltu0fPPPy9Juu6669SgQQN1795dkydPVsuWLT1eNwAAdZ3XZv4BAQGKi4tTZmamU3tmZqYSEhKqXOaf//ynfH2dS/bz85P02xEDwBWX62/0AHA+Xj3sn5KSonnz5mn+/PnKzc3VmDFjlJ+f7ziMn5qaqgEDBjj633fffVq2bJnmzJmj3bt367vvvtPIkSN10003KTIy0lu7AQBAneK1w/6S1L9/fx09elSTJk1SQUGBYmJilJGRoaioKElSQUGB0z3/SUlJKi4u1qxZszR27Fg1btxYPXv21H/+5396axcAwGtKSkrUsGFDSdLJkyfVoEEDL1eEusLHWHa8vKioSKGhoTpx4gQX/1mOH5yo6/gOe15dG+OaZpzXr/YHAAC1i/AHAMAyhD8AAJbx6gV/QE21/cPf3L7OirL/c/y748tfyDcgyK3r3zul+j87DQDeRPgDAC4b7p4oeHqSIHlnosBh/0sUf4AGAOAphD8AAJYh/AF4DEewgEsT4Q8AgGUIfwAALEP4AwBgGW71g7V8A4IUNe4zb5cBALWOmT8AAJYh/AEAsAyH/QEAqMblenqQmT8AAJZh5g8AtYS/O49LBTN/AAAsw8wfgCQemwzYhPB3A35oAgDqEg77AwBgGcIfAADLEP4AAFiG8AcAwDKEPwAAliH8AQCwDOEPAIBlCH8AACxD+AMAYBnCHwAAy/DnfQF4zOX6LHSgrmPmDwCAZQh/AAAsw2H/SxSHSwEAnkL4A0AdxSQBF4rD/gAAWIbwBwDAMoQ/AACWIfwBALAM4Q8AgGUIfwAALEP4AwBgGcIfAADLEP4AAFiG8AcAwDKEPwAAliH8AQCwDOEPAIBlCH8AACxD+AMAYBnCHwAAyxD+AABYhvAHAMAyhD8AAJYh/AEAsAzhDwCAZQh/AAAs4/Xwnz17tqKjoxUUFKS4uDitW7funP1LS0s1fvx4RUVFKTAwUFdeeaXmz59fS9UCAFD3+Xtz4+np6Ro9erRmz56tW265RX/+85/Vp08fbd++XW3atKlymUcffVS//PKL3n33XV111VU6fPiwzpw5U8uVAwBQd3k1/KdOnapBgwZp8ODBkqTp06fryy+/1Jw5c5SWllap/xdffKE1a9Zo9+7datq0qSSpbdu2tVkyAAB1ntcO+5eVlSkrK0uJiYlO7YmJiVq/fn2Vy6xYsUJdunTR66+/riuuuEJXX321nnvuOZ06dara7ZSWlqqoqMjpBQCAzbw28z9y5IjKy8sVHh7u1B4eHq7CwsIql9m9e7e+/fZbBQUFafny5Tpy5IiGDh2qY8eOVXvePy0tTRMnTnR7/QAA1FVev+DPx8fH6b0xplLbWRUVFfLx8dGiRYt00003qW/fvpo6daoWLlxY7ew/NTVVJ06ccLz279/v9n0AAKAu8drMv1mzZvLz86s0yz98+HClowFntWzZUldccYVCQ0MdbR07dpQxRgcOHFD79u0rLRMYGKjAwED3Fg8AQB3mtZl/QECA4uLilJmZ6dSemZmphISEKpe55ZZbdOjQIZ08edLRtnPnTvn6+qpVq1YerRcAgMuFVw/7p6SkaN68eZo/f75yc3M1ZswY5efnKzk5WdJvh+wHDBjg6P/EE08oLCxMTz/9tLZv3661a9fq+eef18CBAxUcHOyt3QAAoE7x6q1+/fv319GjRzVp0iQVFBQoJiZGGRkZioqKkiQVFBQoPz/f0b9hw4bKzMzUiBEj1KVLF4WFhenRRx/V5MmTvbULAADUOS6Hf9u2bTVw4EAlJSVV+4d4XDF06FANHTq0ys8WLlxYqe2aa66pdKoAAADUnMuH/ceOHav/+Z//Ubt27dSrVy8tWbJEpaWlnqgNAAB4gMvhP2LECGVlZSkrK0udOnXSyJEj1bJlSw0fPlybN2/2RI0AAMCNLviCv9jYWM2YMUMHDx7UhAkTNG/ePHXt2lWxsbGaP3++jDHurBMAALjJBV/wd/r0aS1fvlwLFixQZmambr75Zg0aNEiHDh3S+PHj9dVXX+nDDz90Z60AAMANXA7/zZs3a8GCBVq8eLH8/Pz05JNPatq0abrmmmscfRITE3Xbbbe5tVAAAOAeLod/165d1atXL82ZM0f9+vVTvXr1KvXp1KmTHnvsMbcUCAAA3Mvl8N+9e7fjPvzqNGjQQAsWLLjgogAAgOe4fMHf4cOH9f3331dq//7777Vp0ya3FAUAADzH5fAfNmxYlU/GO3jwoIYNG+aWogAAgOe4HP7bt2/XjTfeWKn9hhtu0Pbt291SFAAA8ByXwz8wMFC//PJLpfaCggL5+3v1UQEAAKAGXA7/Xr16KTU1VSdOnHC0HT9+XC+++KJ69erl1uIAAID7uTxVf/PNN3XbbbcpKipKN9xwgyQpJydH4eHh+u///m+3FwgAANzL5fC/4oortGXLFi1atEg//vijgoOD9fTTT+vxxx+v8p5/AABwabmgk/QNGjTQM8884+5aAABALbjgK/S2b9+u/Px8lZWVObXff//9F10UAADwnAv6C38PPvigtm7dKh8fH8fT+3x8fCRJ5eXl7q0QAAC4lctX+48aNUrR0dH65ZdfVL9+fW3btk1r165Vly5dtHr1ag+UCAAA3Mnlmf+GDRu0atUqNW/eXL6+vvL19dWtt96qtLQ0jRw5UtnZ2Z6oEwAAuInLM//y8nI1bNhQktSsWTMdOnRIkhQVFaUdO3a4tzoAAOB2Ls/8Y2JitGXLFrVr107dunXT66+/roCAAL3zzjtq166dJ2oEAABu5HL4v/TSSyopKZEkTZ48Wffee6+6d++usLAwpaenu71AAADgXi6Hf+/evR3/bteunbZv365jx46pSZMmjiv+AQDApculc/5nzpyRv7+/fvrpJ6f2pk2bEvwAANQRLoW/v7+/oqKiuJcfAIA6zOWr/V966SWlpqbq2LFjnqgHAAB4mMvn/N966y39/e9/V2RkpKKiotSgQQOnzzdv3uy24gAAgPu5HP79+vXzQBkAAKC2uBz+EyZM8EQdAACglrh8zh8AANRtLs/8fX19z3lbH3cCAABwaXM5/JcvX+70/vTp08rOztZ7772niRMnuq0wAADgGS6H/wMPPFCp7ZFHHtG1116r9PR0DRo0yC2FAQAAz3DbOf9u3brpq6++ctfqAACAh7gl/E+dOqWZM2eqVatW7lgdAADwIJcP+//7A3yMMSouLlb9+vX1wQcfuLU4AADgfi6H/7Rp05zC39fXV82bN1e3bt3UpEkTtxYHAADcz+XwT0pK8kAZAACgtrh8zn/BggX66KOPKrV/9NFHeu+999xSFAAA8ByXw3/KlClq1qxZpfYWLVrotddec0tRAADAc1wO/3379ik6OrpSe1RUlPLz891SFAAA8ByXw79FixbasmVLpfYff/xRYWFhbikKAAB4jsvh/9hjj2nkyJH65ptvVF5ervLycq1atUqjRo3SY4895okaAQCAG7l8tf/kyZO1b98+3XnnnfL3/23xiooKDRgwgHP+AADUAS6Hf0BAgNLT0zV58mTl5OQoODhYnTt3VlRUlCfqAwAAbuZy+J/Vvn17tW/f3p21AACAWuDyOf9HHnlEU6ZMqdT+xhtv6D/+4z/cUhQAAPAcl8N/zZo1uueeeyq133333Vq7dq1bigIAAJ7jcvifPHlSAQEBldrr1aunoqIitxQFAAA8x+Xwj4mJUXp6eqX2JUuWqFOnTm4pCgAAeI7LF/y9/PLLevjhh7Vr1y717NlTkvT111/rww8/1Mcff+z2AgEAgHu5HP7333+/PvnkE7322mv6+OOPFRwcrNjYWK1atUohISGeqBEAALjRBd3qd8899zgu+jt+/LgWLVqk0aNH68cff1R5eblbCwQAAO7l8jn/s1atWqXf/e53ioyM1KxZs9S3b19t2rTJnbUBAAAPcGnmf+DAAS1cuFDz589XSUmJHn30UZ0+fVpLly7lYj8AAOqIGs/8+/btq06dOmn79u2aOXOmDh06pJkzZ3qyNgAA4AE1nvmvXLlSI0eO1LPPPsuf9QUAoA6r8cx/3bp1Ki4uVpcuXdStWzfNmjVL//jHPzxZGwAA8IAah398fLz+8pe/qKCgQEOGDNGSJUt0xRVXqKKiQpmZmSouLr6gAmbPnq3o6GgFBQUpLi5O69atq9Fy3333nfz9/XX99ddf0HYBALCVy1f7169fXwMHDtS3336rrVu3auzYsZoyZYpatGih+++/36V1paena/To0Ro/fryys7PVvXt39enTR/n5+edc7sSJExowYIDuvPNOV8sHAMB6F3yrnyR16NBBr7/+ug4cOKDFixe7vPzUqVM1aNAgDR48WB07dtT06dPVunVrzZkz55zLDRkyRE888YTi4+MvtHQAAKx1UeF/lp+fn/r166cVK1bUeJmysjJlZWUpMTHRqT0xMVHr16+vdrkFCxZo165dmjBhQo22U1paqqKiIqcXAAA2c0v4X4gjR46ovLxc4eHhTu3h4eEqLCyscpm8vDz94Q9/0KJFi+TvX7MbFdLS0hQaGup4tW7d+qJrBwCgLvNa+J/l4+Pj9N4YU6lNksrLy/XEE09o4sSJuvrqq2u8/tTUVJ04ccLx2r9//0XXDABAXXZBf9vfHZo1ayY/P79Ks/zDhw9XOhogScXFxdq0aZOys7M1fPhwSVJFRYWMMfL399fKlSsdTxn8V4GBgQoMDPTMTgAAUAd5beYfEBCguLg4ZWZmOrVnZmYqISGhUv+QkBBt3bpVOTk5jldycrI6dOignJwcdevWrbZKBwCgTvPazF+SUlJS9OSTT6pLly6Kj4/XO++8o/z8fCUnJ0v67ZD9wYMH9f7778vX11cxMTFOy7do0UJBQUGV2gEAQPW8Gv79+/fX0aNHNWnSJBUUFCgmJkYZGRmKioqSJBUUFJz3nn8AAOAar4a/JA0dOlRDhw6t8rOFCxeec9lXX31Vr776qvuLAgDgMub1q/0BAEDtIvwBALAM4Q8AgGUIfwAALEP4AwBgGcIfAADLEP4AAFiG8AcAwDKEPwAAliH8AQCwDOEPAIBlCH8AACxD+AMAYBnCHwAAyxD+AABYhvAHAMAyhD8AAJYh/AEAsAzhDwCAZQh/AAAsQ/gDAGAZwh8AAMsQ/gAAWIbwBwDAMoQ/AACWIfwBALAM4Q8AgGUIfwAALEP4AwBgGcIfAADLEP4AAFiG8AcAwDKEPwAAliH8AQCwDOEPAIBlCH8AACxD+AMAYBnCHwAAyxD+AABYhvAHAMAyhD8AAJYh/AEAsAzhDwCAZQh/AAAsQ/gDAGAZwh8AAMsQ/gAAWIbwBwDAMoQ/AACWIfwBALAM4Q8AgGUIfwAALEP4AwBgGcIfAADLEP4AAFiG8AcAwDKEPwAAlvF6+M+ePVvR0dEKCgpSXFyc1q1bV23fZcuWqVevXmrevLlCQkIUHx+vL7/8sharBQCg7vNq+Kenp2v06NEaP368srOz1b17d/Xp00f5+flV9l+7dq169eqljIwMZWVl6Y477tB9992n7OzsWq4cAIC6y6vhP3XqVA0aNEiDBw9Wx44dNX36dLVu3Vpz5sypsv/06dP1wgsvqGvXrmrfvr1ee+01tW/fXp9++mktVw4AQN3ltfAvKytTVlaWEhMTndoTExO1fv36Gq2joqJCxcXFatq0abV9SktLVVRU5PQCAMBmXgv/I0eOqLy8XOHh4U7t4eHhKiwsrNE63nzzTZWUlOjRRx+ttk9aWppCQ0Mdr9atW19U3QAA1HVev+DPx8fH6b0xplJbVRYvXqxXX31V6enpatGiRbX9UlNTdeLECcdr//79F10zAAB1mb+3NtysWTP5+flVmuUfPny40tGAf5eenq5Bgwbpo48+0l133XXOvoGBgQoMDLzoegEAuFx4beYfEBCguLg4ZWZmOrVnZmYqISGh2uUWL16spKQkffjhh7rnnns8XSYAAJcdr838JSklJUVPPvmkunTpovj4eL3zzjvKz89XcnKypN8O2R88eFDvv/++pN+Cf8CAAZoxY4Zuvvlmx1GD4OBghYaGem0/AACoS7wa/v3799fRo0c1adIkFRQUKCYmRhkZGYqKipIkFRQUON3z/+c//1lnzpzRsGHDNGzYMEf7U089pYULF9Z2+QAA1EleDX9JGjp0qIYOHVrlZ/8e6KtXr/Z8QQAAXOa8frU/AACoXYQ/AACWIfwBALAM4Q8AgGUIfwAALEP4AwBgGcIfAADLEP4AAFiG8AcAwDKEPwAAliH8AQCwDOEPAIBlCH8AACxD+AMAYBnCHwAAyxD+AABYhvAHAMAyhD8AAJYh/AEAsAzhDwCAZQh/AAAsQ/gDAGAZwh8AAMsQ/gAAWIbwBwDAMoQ/AACWIfwBALAM4Q8AgGUIfwAALEP4AwBgGcIfAADLEP4AAFiG8AcAwDKEPwAAliH8AQCwDOEPAIBlCH8AACxD+AMAYBnCHwAAyxD+AABYhvAHAMAyhD8AAJYh/AEAsAzhDwCAZQh/AAAsQ/gDAGAZwh8AAMsQ/gAAWIbwBwDAMoQ/AACWIfwBALAM4Q8AgGUIfwAALEP4AwBgGcIfAADLEP4AAFiG8AcAwDKEPwAAlvF6+M+ePVvR0dEKCgpSXFyc1q1bd87+a9asUVxcnIKCgtSuXTvNnTu3lioFAODy4NXwT09P1+jRozV+/HhlZ2ere/fu6tOnj/Lz86vsv2fPHvXt21fdu3dXdna2XnzxRY0cOVJLly6t5coBAKi7vBr+U6dO1aBBgzR48GB17NhR06dPV+vWrTVnzpwq+8+dO1dt2rTR9OnT1bFjRw0ePFgDBw7Uf/3Xf9Vy5QAA1F3+3tpwWVmZsrKy9Ic//MGpPTExUevXr69ymQ0bNigxMdGprXfv3nr33Xd1+vRp1atXr9IypaWlKi0tdbw/ceKEJKmoqOhid8GhovSfbltXbXHn/tcGxtjzGGPPY4w9z/YxPrsuY8w5+3kt/I8cOaLy8nKFh4c7tYeHh6uwsLDKZQoLC6vsf+bMGR05ckQtW7astExaWpomTpxYqb1169YXUX3dFzrd2xVc/hhjz2OMPY8x9jxPjHFxcbFCQ0Or/dxr4X+Wj4+P03tjTKW28/Wvqv2s1NRUpaSkON5XVFTo2LFjCgsLO+d2LgVFRUVq3bq19u/fr5CQEG+Xc1lijD2PMfYsxtfz6tIYG2NUXFysyMjIc/bzWvg3a9ZMfn5+lWb5hw8frjS7PysiIqLK/v7+/goLC6tymcDAQAUGBjq1NW7c+MIL94KQkJBL/gtX1zHGnscYexbj63l1ZYzPNeM/y2sX/AUEBCguLk6ZmZlO7ZmZmUpISKhymfj4+Er9V65cqS5dulR5vh8AAFTm1av9U1JSNG/ePM2fP1+5ubkaM2aM8vPzlZycLOm3Q/YDBgxw9E9OTta+ffuUkpKi3NxczZ8/X++++66ee+45b+0CAAB1jlfP+ffv319Hjx7VpEmTVFBQoJiYGGVkZCgqKkqSVFBQ4HTPf3R0tDIyMjRmzBi9/fbbioyM1FtvvaWHH37YW7vgUYGBgZowYUKl0xZwH8bY8xhjz2J8Pe9yHGMfc777AQAAwGXF63/eFwAA1C7CHwAAyxD+AABYhvAHAMAyhL+XrV27Vvfdd58iIyPl4+OjTz75xOlzY4xeffVVRUZGKjg4WD169NC2bdu8U2wdlZaWpq5du6pRo0Zq0aKF+vXrpx07djj1YZwvzpw5c3Tdddc5/ghKfHy8Pv/8c8fnjO/Fe/XVV+Xj4+P0ioiIcHzOGLvOHT9/S0tLNWLECDVr1kwNGjTQ/fffrwMHDtTiXlwYwt/LSkpKFBsbq1mzZlX5+euvv66pU6dq1qxZ+uGHHxQREaFevXqpuLi4liutu9asWaNhw4Zp48aNyszM1JkzZ5SYmKiSkhJHH8b54rRq1UpTpkzRpk2btGnTJvXs2VMPPPCA4wcl4+se1157rQoKChyvrVu3Oj5jjF3njp+/o0eP1vLly7VkyRJ9++23OnnypO69916Vl5fX1m5cGINLhiSzfPlyx/uKigoTERFhpkyZ4mj7v//7PxMaGmrmzp3rhQovD4cPHzaSzJo1a4wxjLOnNGnSxMybN4/xdZMJEyaY2NjYKj9jjC/ehfz8PX78uKlXr55ZsmSJo8/BgweNr6+v+eKLL2qt9gvBzP8StmfPHhUWFjo9xjgwMFC33357tY89xvmdfaxz06ZNJTHO7lZeXq4lS5aopKRE8fHxjK8b5eXlKTIyUtHR0Xrssce0e/duSXyHPaEmY5qVlaXTp0879YmMjFRMTMwlP+6E/yXs7EOMXHnsMc7NGKOUlBTdeuutiomJkcQ4u8vWrVvVsGFDBQYGKjk5WcuXL1enTp0YXzfp1q2b3n//fX355Zf6y1/+osLCQiUkJOjo0aOMsQfUZEwLCwsVEBCgJk2aVNvnUuX1R/ri/Fx97DGqN3z4cG3ZskXffvttpc8Y54vToUMH5eTk6Pjx41q6dKmeeuoprVmzxvE543tx+vTp4/h3586dFR8fryuvvFLvvfeebr75ZkmMsSdcyJjWhXFn5n8JO3slryuPPUb1RowYoRUrVuibb75Rq1atHO2Ms3sEBAToqquuUpcuXZSWlqbY2FjNmDGD8fWQBg0aqHPnzsrLy2OMPaAmYxoREaGysjL9+uuv1fa5VBH+l7Do6GhFREQ4Pca4rKxMa9asqfaxx6jMGKPhw4dr2bJlWrVqlaKjo50+Z5w9wxij0tJSxtdDSktLlZubq5YtWzLGHlCTMY2Li1O9evWc+hQUFOinn3669Mfda5cawhhjTHFxscnOzjbZ2dlGkpk6darJzs42+/btM8YYM2XKFBMaGmqWLVtmtm7dah5//HHTsmVLU1RU5OXK645nn33WhIaGmtWrV5uCggLH65///KejD+N8cVJTU83atWvNnj17zJYtW8yLL75ofH19zcqVK40xjK87jB071qxevdrs3r3bbNy40dx7772mUaNGZu/evcYYxvhCuOPnb3JysmnVqpX56quvzObNm03Pnj1NbGysOXPmjLd2q0YIfy/75ptvjKRKr6eeesoY89vtJhMmTDAREREmMDDQ3HbbbWbr1q3eLbqOqWp8JZkFCxY4+jDOF2fgwIEmKirKBAQEmObNm5s777zTEfzGML7u0L9/f9OyZUtTr149ExkZaR566CGzbds2x+eMsevc8fP31KlTZvjw4aZp06YmODjY3HvvvSY/P98Le+MaHukLAIBlOOcPAIBlCH8AACxD+AMAYBnCHwAAyxD+AABYhvAHAMAyhD8AAJYh/AEAsAzhD1zmFi5cqMaNG3u7DIfVq1fLx8dHx48f93YptcrW/califCH9Xx8fM75SkpK8lptbdu21fTp0722/UtFjx49NHr0aG+XAVw2/L1dAOBtBQUFjn+np6frlVde0Y4dOxxtwcHBLq2vrKxMAQEBbqsPOBe+b7gQzPxhvYiICMcrNDRUPj4+jvf16tVTcnKyWrVqpfr166tz585avHix0/I9evTQ8OHDlZKSombNmqlXr16SpBUrVqh9+/YKDg7WHXfcoffee6/SYd/169frtttuU3BwsFq3bq2RI0eqpKTEsd59+/ZpzJgxjqMQ1Tl+/LieeeYZhYeHKygoSDExMfrss8+q7Ltr1y498MADCg8PV8OGDdW1a1d99dVXTn1mz56t9u3bKygoSOHh4XrkkUccn3388cfq3LmzgoODFRYWprvuustRc1UyMjJ09dVXO8Zh7969Tp8fPXpUjz/+eLVjnJSUpDVr1mjGjBmOcdi7d6/Ky8s1aNAgRUdHKzg4WB06dNCMGTOqrUP6/4fev/76a3Xp0kX169dXQkKC0y97SUlJ6tevn9Nyo0ePVo8ePRzve/TooREjRmj06NFq0qSJwsPD9c4776ikpERPP/20GjVqpCuvvFKff/55pRq+++47xcbGKigoSN26ddPWrVudPj/Xd0L67WjQ5MmTlZSUpNDQUP3+978/5z4DVfL2k4WAS8mCBQtMaGio4/2BAwfMG2+8YbKzs82uXbvMW2+9Zfz8/MzGjRsdfW6//XbTsGFD8/zzz5uff/7Z5Obmmj179ph69eqZ5557zvz8889m8eLF5oorrjCSzK+//mqMMWbLli2mYcOGZtq0aWbnzp3mu+++MzfccINJSkoyxhhz9OhR06pVKzNp0iTHY4irUl5ebm6++WZz7bXXmpUrV5pdu3aZTz/91GRkZFS5Tzk5OWbu3Llmy5YtZufOnWb8+PEmKCjI8RjTH374wfj5+ZkPP/zQ7N2712zevNnMmDHDGGPMoUOHjL+/v5k6darj8b1vv/22KS4urrK2/Px8ExgYaEaNGmV+/vln88EHH5jw8HCncTjfGB8/ftzEx8eb3//+945xOHPmjCkrKzOvvPKK+d///V+ze/du88EHH5j69eub9PT0av9/zz7FrVu3bmb16tVm27Ztpnv37iYhIcHR56mnnjIPPPCA03KjRo0yt99+u9P/eaNGjcwf//hHs3PnTvPHP/7R+Pr6mj59+ph33nnH7Ny50zz77LMmLCzMlJSUOG27Y8eOZuXKlWbLli3m3nvvNW3btjVlZWU1+k4YY0xUVJQJCQkxb7zxhsnLyzN5eXnV7i9QHcIf+Bf/HpRV6du3rxk7dqzj/e23326uv/56pz7jxo0zMTExTm3jx493Cr0nn3zSPPPMM0591q1bZ3x9fc2pU6eMMb/9oJ82bdo56/nyyy+Nr6+v2bFjxwXvU6dOnczMmTONMcYsXbrUhISEVPkc+KysLCPJ8Qz580lNTTUdO3Y0FRUVjrZx48Y5jUNVqhrjUaNGnXd7Q4cONQ8//HC1n58N4K+++srR9re//c1Icox5TcP/1ltvdbw/c+aMadCggXnyyScdbQUFBUaS2bBhg9O2lyxZ4uhz9OhRExwc7PiFpabfiX79+p13LIBz4Zw/cA7l5eWaMmWK0tPTdfDgQZWWlqq0tFQNGjRw6telSxen9zt27FDXrl2d2m666San91lZWfr73/+uRYsWOdqMMaqoqNCePXvUsWPHGtWYk5OjVq1a6eqrr65R/5KSEk2cOFGfffaZDh06pDNnzujUqVPKz8+XJPXq1UtRUVFq166d7r77bt1999168MEHVb9+fcXGxurOO+9U586d1bt3byUmJuqRRx5RkyZNqtxWbm6ubr75ZqdTFvHx8U59ajrGVZk7d67mzZunffv26dSpUyorK9P1119/3uWuu+46x79btmwpSTp8+LDatGlz3mWrWoefn5/CwsLUuXNnR1t4eLhjvf/qX/e/adOm6tChg3JzcyXV/Dvx7983wFWc8wfO4c0339S0adP0wgsvaNWqVcrJyVHv3r1VVlbm1O/fg8oYU+kcvTHG6X1FRYWGDBminJwcx+vHH39UXl6errzyyhrX6OoFic8//7yWLl2qP/3pT1q3bp1ycnLUuXNnxz41atRImzdv1uLFi9WyZUu98sorio2N1fHjx+Xn56fMzEx9/vnn6tSpk2bOnKkOHTpoz549VW7r3/e5KjUd43/317/+VWPGjNHAgQO1cuVK5eTk6Omnnz7vcpJUr149x7/P/j9VVFRIknx9fSvVffr06XOu4+x6zrXec/nXvjX5TtTkFyPgXJj5A+ewbt06PfDAA/rd734n6bcfznl5eeedlV9zzTXKyMhwatu0aZPT+xtvvFHbtm3TVVddVe16AgICVF5efs5tXXfddTpw4IB27txZo9n/unXrlJSUpAcffFCSdPLkyUoX4fn7++uuu+7SXXfdpQkTJqhx48ZatWqVHnroIfn4+OiWW27RLbfcoldeeUVRUVFavny5UlJSKm2rU6dO+uSTT5zaNm7cWKme841xVeOwbt06JSQkaOjQoY62Xbt2nXf/z6d58+b66aefnNpycnIqhf2F2rhxo+MIw6+//qqdO3fqmmuukVSz7wTgDsz8gXO46qqrlJmZqfXr1ys3N1dDhgxRYWHheZcbMmSIfv75Z40bN047d+7UX//6Vy1cuFDS/5/ljRs3Ths2bNCwYcOUk5OjvLw8rVixQiNGjHCsp23btlq7dq0OHjyoI0eOVLmt22+/XbfddpsefvhhZWZmas+ePfr888/1xRdfVLtPy5Ytc8wqn3jiCafZ6Weffaa33npLOTk52rdvn95//31VVFSoQ4cO+v777/Xaa69p06ZNys/P17Jly/SPf/yj2l+GkpOTtWvXLqWkpGjHjh368MMPHePgyhi3bdtW33//vfbu3asjR46ooqJCV111lTZt2qQvv/xSO3fu1Msvv6wffvjhnP8vNdGzZ09t2rRJ77//vvLy8jRhwoRKvwxcjEmTJunrr7/WTz/9pKSkJDVr1sxxd0FNvhOAOxD+wDm8/PLLuvHGG9W7d2/16NFDERERlW4Dq0p0dLQ+/vhjLVu2TNddd53mzJmj8ePHS5ICAwMl/TZjX7NmjfLy8tS9e3fdcMMNevnllx3noKXfgmLv3r268sor1bx582q3t3TpUnXt2lWPP/64OnXqpBdeeKHaIwbTpk1TkyZNlJCQoPvuu0+9e/fWjTfe6Pi8cePGWrZsmXr27KmOHTtq7ty5Wrx4sa699lqFhIRo7dq16tu3r66++mq99NJLevPNN9WnT58qt9WmTRstXbpUn376qWJjYzV37ly99tprLo/xc889Jz8/P3Xq1EnNmzdXfn6+kpOT9dBDD6l///7q1q2bjh496nQU4EL17t1bL7/8sl544QV17dpVxcXFGjBgwEWv96wpU6Zo1KhRiouLU0FBgVasWOG4T78m3wnAHXxMTU7KAbhof/rTnzR37lzt37/f26UAsBzn/AEPmT17trp27aqwsDB99913euONNzR8+HBvlwUAhD/gKXl5eZo8ebKOHTumNm3aaOzYsUpNTfV2WQDAYX8AAGzDBX8AAFiG8AcAwDKEPwAAliH8AQCwDOEPAIBlCH8AACxD+AMAYBnCHwAAy/w/GQHnHFkxdh4AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 500x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class_name = 4\n",
    "\n",
    "fig, ax = plt.subplots(layout='constrained', figsize=(5, 4))\n",
    "\n",
    "sampling_size_list = [10, 20, 30, 50, 100]\n",
    "\n",
    "width = 0.5  # the width of the bars\n",
    "multiplier = 1.5\n",
    "x = np.arange(len(sampling_size_list))\n",
    "\n",
    "new_acc_list = []\n",
    "for k in sampling_size_list:\n",
    "    v = acc_result_dict[(class_name, k)]\n",
    "    new_acc_list.append(v)\n",
    "\n",
    "print(new_acc_list)\n",
    "mean = np.mean(new_acc_list, axis = 1)\n",
    "std = np.std(new_acc_list, axis = 1)\n",
    "\n",
    "print(mean, std)\n",
    "\n",
    "offset = width * multiplier\n",
    "rects = ax.bar(x + offset, mean, width, label=str(k), align=\"edge\")\n",
    "ax.errorbar(x + offset + width/2, mean, std, linestyle='None', fmt='-', color=\"black\")\n",
    "multiplier += 1\n",
    "\n",
    "ax.set_ylim(0, 1)\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.set_xlabel('Target class data number')\n",
    "ax.set_title(f'')\n",
    "ax.set_xticks(x + width*2, sampling_size_list)\n",
    "# ax.legend(loc='upper left', ncols=4, title=\"Sampling Method\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
