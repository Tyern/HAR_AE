{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import lightning as L\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from data_module.data_module import FFTDataModule\n",
    "from model.enc_classifier_model import AE1DClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_seed = 42\n",
    "L.seed_everything(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 20000\n",
    "patience = n_epochs//100\n",
    "\n",
    "optimizer_param_dict = {\n",
    "    \"Adam\": (optim.Adam, {\n",
    "        \"lr\": 0.001,\n",
    "    }),\n",
    "    \"SGD\": (optim.SGD, {\n",
    "        \"lr\": 0.001,\n",
    "        \"momentum\": 0.5,\n",
    "    }),\n",
    "}\n",
    "batch_size = 512\n",
    "optimizer, optimizer_param = optimizer_param_dict[\"Adam\"]\n",
    "dataset_path = \"/nfs/ksdata/tran/HAR_AE/dataset/processed_concat_data\"\n",
    "AE1D_ckpt_path = \"lightning_logs/14_AE_5classes/pattern_27/version_0/checkpoints/sample_epoch=3419-step=68400-val_loss=0.000000.ckpt\"\n",
    "\n",
    "log_save_dir = \"lightning_logs/15_enc_classify_5classes_AEpattern27\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\" ----------------------start training---------------------------\")\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "from lightning.pytorch.loggers import TensorBoardLogger, CSVLogger\n",
    "from lightning.pytorch.utilities.model_summary import ModelSummary\n",
    "\n",
    "def train_one_model(net, model_name):\n",
    "    tensorboard_logger = TensorBoardLogger(save_dir=log_save_dir, name=model_name,)\n",
    "    csv_logger = CSVLogger(save_dir=log_save_dir, name=model_name,)\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        dirpath=None,\n",
    "        save_top_k=1,\n",
    "        monitor=\"val_loss\",\n",
    "        mode=\"min\",\n",
    "        filename=\"sample_{epoch:02d}-{step:02d}-{val_loss:02f}\"\n",
    "    )\n",
    "    \n",
    "    trainer = L.Trainer(\n",
    "        logger=[tensorboard_logger, csv_logger],\n",
    "        callbacks=[EarlyStopping(monitor=\"val_loss\", patience=patience), checkpoint_callback],\n",
    "        max_epochs=n_epochs,\n",
    "        check_val_every_n_epoch=10,\n",
    "        accelerator=\"auto\"\n",
    "        )\n",
    "    \n",
    "    data_module = FFTDataModule(dataset_path=dataset_path, batch_size=batch_size)\n",
    "    \n",
    "    trainer.fit(model=net, datamodule=data_module)\n",
    "    trainer_test_dict = trainer.logged_metrics\n",
    "    \n",
    "    trainer.test(model=net, datamodule=data_module)\n",
    "    trainer_test_dict.update(trainer.logged_metrics)\n",
    "\n",
    "    for key in trainer_test_dict.keys():\n",
    "        trainer_test_dict[key] = trainer_test_dict[key].item()\n",
    "    \n",
    "    with open(os.path.join(trainer.logger.log_dir, \"result.json\"), \"w\") as f:\n",
    "        json.dump(trainer_test_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_filter_list = [\n",
    "    {\"linear_channel_param\": [128, 64], \"is_dropout\": False, },\n",
    "    {\"linear_channel_param\": [64, 32], \"is_dropout\": False, },\n",
    "    {\"linear_channel_param\": [128, 64], \"is_dropout\": True, },\n",
    "    {\"linear_channel_param\": [64, 32], \"is_dropout\": True, },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser(description=\"\", formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n",
    "\n",
    "parser.add_argument(\"--idx\", type=int, default=0,\n",
    "                    help=f\"learning pattern min=0, max={len(run_filter_list) - 1}\")\n",
    "\n",
    "if os.path.basename(sys.argv[0]) == 'ipykernel_launcher.py':\n",
    "    args = parser.parse_args(args=[])\n",
    "else:\n",
    "    args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_filters, linear_filters = run_filter_list[args.idx]\n",
    "net = AE1DClassifier(\n",
    "    AE1D_ckpt_path = AE1D_ckpt_path,\n",
    "    optimizer = optimizer,\n",
    "    optimizer_param = optimizer_param, \n",
    "    out_features = 5,\n",
    "    **run_filter_list[args.idx],\n",
    ")\n",
    "model_summary = ModelSummary(net, max_depth=6)\n",
    "print(model_summary)\n",
    "\n",
    "train_one_model(net, model_name=f\"pattern_{args.idx}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
