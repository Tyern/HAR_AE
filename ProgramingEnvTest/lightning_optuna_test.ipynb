{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import lightning as L\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import optuna\n",
    "from optuna.integration.pytorch_lightning import PyTorchLightningPruningCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST = False\n",
    "\n",
    "n_epochs = 1\n",
    "batch_size_train = 64\n",
    "batch_size_test = 1000\n",
    "learning_rate = 0.01\n",
    "momentum = 0.5\n",
    "log_interval = 10\n",
    "\n",
    "random_seed = 1\n",
    "L.seed_everything(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightning.pytorch.utilities.types import EVAL_DATALOADERS, TRAIN_DATALOADERS\n",
    "\n",
    "\n",
    "class DataModule(L.LightningDataModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "    \n",
    "    def setup(self, stage=None):\n",
    "        self.train_set = torchvision.datasets.MNIST(\n",
    "            './files/', train=True, download=True,\n",
    "            transform=torchvision.transforms.Compose([\n",
    "            torchvision.transforms.ToTensor(),\n",
    "            torchvision.transforms.Normalize(\n",
    "                (0.1307,), (0.3081,))\n",
    "            ]))\n",
    "        \n",
    "        self.test_set = torchvision.datasets.MNIST(\n",
    "            './files/', train=False, download=True,\n",
    "            transform=torchvision.transforms.Compose([\n",
    "            torchvision.transforms.ToTensor(),\n",
    "            torchvision.transforms.Normalize(\n",
    "                (0.1307,), (0.3081,))\n",
    "            ]))\n",
    "        \n",
    "    def train_dataloader(self) -> TRAIN_DATALOADERS:\n",
    "        return torch.utils.data.DataLoader(\n",
    "            self.train_set, batch_size=batch_size_train, shuffle=True)\n",
    "    \n",
    "    def val_dataloader(self) -> EVAL_DATALOADERS:\n",
    "        return torch.utils.data.DataLoader(\n",
    "            self.test_set, batch_size=batch_size_test, shuffle=False)\n",
    "\n",
    "    def test_dataloader(self) -> EVAL_DATALOADERS:\n",
    "        return torch.utils.data.DataLoader(\n",
    "            self.test_set, batch_size=batch_size_test, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "from lightning.pytorch.utilities.types import STEP_OUTPUT, OptimizerLRScheduler\n",
    "\n",
    "class Net(L.LightningModule):\n",
    "    def __init__(self, lr):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.example_input_array = torch.rand(10, 1, 28, 28)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x)\n",
    "    \n",
    "    def configure_optimizers(self) -> OptimizerLRScheduler:\n",
    "        return optim.SGD(self.parameters(), lr=self.hparams.lr,\n",
    "                      momentum=momentum)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx) -> STEP_OUTPUT:\n",
    "        x, y = batch\n",
    "        output = self.forward(x)\n",
    "        loss = F.nll_loss(output, y)\n",
    "\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self,  batch, batch_idx) -> STEP_OUTPUT:\n",
    "        x, y = batch\n",
    "        output = self.forward(x)\n",
    "        loss = F.nll_loss(output, y)\n",
    "        self.log(\"val_loss\", loss)\n",
    "\n",
    "        acc = (torch.argmax(output, dim=1) == y).sum()/len(y)\n",
    "        self.log(\"val_acc\", acc)\n",
    "\n",
    "    def test_step(self,  batch, batch_idx) -> STEP_OUTPUT:\n",
    "        x, y = batch\n",
    "        output = self.forward(x)\n",
    "        loss = F.nll_loss(output, y)\n",
    "        self.log(\"test_loss\", loss)\n",
    "\n",
    "        acc = (torch.argmax(output, dim=1) == y).sum()/len(y)\n",
    "        self.log(\"test_acc\", acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial: optuna.trial.Trial):\n",
    "    lr = trial.suggest_categorical(\"lr\", [0.001, 0.01])\n",
    "    net = Net(lr=lr)\n",
    "    data_module = DataModule() \n",
    "\n",
    "    trainer = L.Trainer(\n",
    "        max_epochs=n_epochs,\n",
    "        accelerator=\"gpu\",\n",
    "        # callbacks=[PyTorchLightningPruningCallback(trial, monitor=\"val_loss\")],\n",
    "        )\n",
    "    trainer.fit(model=net, datamodule=data_module)\n",
    "    # trainer.test(model=net, datamodule=data_module)\n",
    "\n",
    "    trainer_test_dict = trainer.logged_metrics\n",
    "    return trainer_test_dict[\"val_loss\"].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pruner: optuna.pruners.BasePruner = (optuna.pruners.MedianPruner())\n",
    "\n",
    "study = optuna.create_study(direction=\"minimize\", pruner=pruner)\n",
    "study.optimize(objective, n_trials=2)\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "for key, val in trial.params.items():\n",
    "    print(\"{}: {}\".format(key, val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
