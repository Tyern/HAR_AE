{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfs/ksdata/tran/miniconda3/envs/python_3.8/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import lightning as L\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score\n",
    "\n",
    "from utils.model_utils import unwrap_model\n",
    "from config.optimizer_param_config import optimizer_param_dict\n",
    "from config.channel_param_config import channel_param_dict, enc_linear_param_dict\n",
    "\n",
    "from data_module.data_module import ALDataModule_v1\n",
    "from model.enc_classifier_model import AE1DClassifier, AE1DMaxPoolBNClassifierModel\n",
    "from model.AE_model import AECNN1DBNModel, AE1DMaxPoolBNModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser(description=\"\", formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n",
    "\n",
    "parser.add_argument(\"-tl\", \"--train_limit_data\", type=int, default=1000,\n",
    "                    help=f\"Used for limit the number of data in train data, -1 mean no limit\")\n",
    "\n",
    "parser.add_argument(\"-cn\", \"--class_num\", type=int, default=8,\n",
    "                    help=f\"Number of class num use to train\")\n",
    "\n",
    "parser.add_argument(\"--model_name\", type=str, default=\"4cnn_64-8-1000-64\",\n",
    "                    help=f\"Config name of model used for training\")\n",
    "\n",
    "parser.add_argument(\"--AE_ckpt_path\", type=str, default=\"/nfs/ksdata/tran/HAR_AE/lightning_logs/11.1_AE/4cnn_64-8-1000-64/version_0/checkpoints/sample_epoch=2269-step=9080-val_loss=0.000000.ckpt\",\n",
    "                    help=f\"Config name of model used for training\")\n",
    "\n",
    "parser.add_argument(\"--linear_param\", type=str, default=\"32\",\n",
    "                    help=f\"Linear config name of model used for training\")\n",
    "\n",
    "parser.add_argument(\"-r\", \"--random_seed\", type=int, default=42,\n",
    "                    help=f\"Random Seed\")\n",
    "\n",
    "parser.add_argument(\"--eval_mode\", type=int, default=0,\n",
    "                    help=f\"Eval all models\")\n",
    "\n",
    "if os.path.basename(sys.argv[0]) == 'ipykernel_launcher.py':\n",
    "    args = parser.parse_args(args=[])\n",
    "else:\n",
    "    args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_seed = 42\n",
    "L.seed_everything(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   | Name                             | Type               | Params | In sizes     | Out sizes   \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "0  | feature_extractor                | AE1DMaxPoolBNModel | 665 K  | ?            | ?           \n",
      "1  | feature_extractor.enc_cnn        | Sequential         | 316 K  | [10, 6, 257] | [10, 256, 1]\n",
      "2  | feature_extractor.enc_cnn.0      | Conv1d             | 1.6 K  | [10, 6, 257] | [10, 32, 84]\n",
      "3  | feature_extractor.enc_cnn.1      | BatchNorm1d        | 64     | [10, 32, 84] | [10, 32, 84]\n",
      "4  | feature_extractor.enc_cnn.2      | ReLU               | 0      | [10, 32, 84] | [10, 32, 84]\n",
      "5  | feature_extractor.enc_cnn.3      | Conv1d             | 18.5 K | [10, 32, 84] | [10, 64, 26]\n",
      "6  | feature_extractor.enc_cnn.4      | BatchNorm1d        | 128    | [10, 64, 26] | [10, 64, 26]\n",
      "7  | feature_extractor.enc_cnn.5      | ReLU               | 0      | [10, 64, 26] | [10, 64, 26]\n",
      "8  | feature_extractor.enc_cnn.6      | Conv1d             | 65.7 K | [10, 64, 26] | [10, 128, 7]\n",
      "9  | feature_extractor.enc_cnn.7      | BatchNorm1d        | 256    | [10, 128, 7] | [10, 128, 7]\n",
      "10 | feature_extractor.enc_cnn.8      | ReLU               | 0      | [10, 128, 7] | [10, 128, 7]\n",
      "11 | feature_extractor.enc_cnn.9      | Conv1d             | 229 K  | [10, 128, 7] | [10, 256, 1]\n",
      "12 | feature_extractor.enc_cnn.10     | BatchNorm1d        | 512    | [10, 256, 1] | [10, 256, 1]\n",
      "13 | feature_extractor.enc_cnn.11     | ReLU               | 0      | [10, 256, 1] | [10, 256, 1]\n",
      "14 | feature_extractor.enc_linear     | Sequential         | 16.6 K | [10, 256]    | [10, 64]    \n",
      "15 | feature_extractor.enc_linear.0   | Linear             | 16.4 K | [10, 256]    | [10, 64]    \n",
      "16 | feature_extractor.enc_linear.1   | BatchNorm1d        | 128    | [10, 64]     | [10, 64]    \n",
      "17 | feature_extractor.enc_linear.2   | ReLU               | 0      | [10, 64]     | [10, 64]    \n",
      "18 | feature_extractor.dec_linear     | Sequential         | 17.2 K | ?            | ?           \n",
      "19 | feature_extractor.dec_linear.0   | Sequential         | 17.2 K | ?            | ?           \n",
      "20 | feature_extractor.dec_linear.0.0 | Linear             | 16.6 K | ?            | ?           \n",
      "21 | feature_extractor.dec_linear.0.1 | BatchNorm1d        | 512    | ?            | ?           \n",
      "22 | feature_extractor.dec_linear.0.2 | ReLU               | 0      | ?            | ?           \n",
      "23 | feature_extractor.dec_cnn        | Sequential         | 315 K  | ?            | ?           \n",
      "24 | feature_extractor.dec_cnn.0      | ConvTranspose1d    | 229 K  | ?            | ?           \n",
      "25 | feature_extractor.dec_cnn.1      | BatchNorm1d        | 256    | ?            | ?           \n",
      "26 | feature_extractor.dec_cnn.2      | ReLU               | 0      | ?            | ?           \n",
      "27 | feature_extractor.dec_cnn.3      | ConvTranspose1d    | 65.6 K | ?            | ?           \n",
      "28 | feature_extractor.dec_cnn.4      | BatchNorm1d        | 128    | ?            | ?           \n",
      "29 | feature_extractor.dec_cnn.5      | ReLU               | 0      | ?            | ?           \n",
      "30 | feature_extractor.dec_cnn.6      | ConvTranspose1d    | 18.5 K | ?            | ?           \n",
      "31 | feature_extractor.dec_cnn.7      | BatchNorm1d        | 64     | ?            | ?           \n",
      "32 | feature_extractor.dec_cnn.8      | ReLU               | 0      | ?            | ?           \n",
      "33 | feature_extractor.dec_cnn.9      | ConvTranspose1d    | 1.5 K  | ?            | ?           \n",
      "34 | feature_extractor.dec_cnn.10     | BatchNorm1d        | 12     | ?            | ?           \n",
      "35 | feature_extractor.dec_cnn.11     | ReLU               | 0      | ?            | ?           \n",
      "36 | classifier_linear                | Sequential         | 2.4 K  | [10, 64]     | [10, 8]     \n",
      "37 | classifier_linear.0              | Linear             | 2.1 K  | [10, 64]     | [10, 32]    \n",
      "38 | classifier_linear.1              | BatchNorm1d        | 64     | [10, 32]     | [10, 32]    \n",
      "39 | classifier_linear.2              | ReLU               | 0      | [10, 32]     | [10, 32]    \n",
      "40 | classifier_linear.3              | Linear             | 264    | [10, 32]     | [10, 8]     \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "2.4 K     Trainable params\n",
      "665 K     Non-trainable params\n",
      "668 K     Total params\n",
      "2.672     Total estimated model params size (MB)\n"
     ]
    }
   ],
   "source": [
    "from lightning.pytorch.utilities.model_summary import ModelSummary\n",
    "\n",
    "net = AE1DMaxPoolBNClassifierModel(\n",
    "    AE1DMaxPoolBN_ckpt_path=args.AE_ckpt_path,\n",
    "    linear_channel_param=enc_linear_param_dict[args.linear_param],\n",
    "    out_features=8\n",
    ").to(\"cpu\")\n",
    "\n",
    "model_summary = ModelSummary(net, max_depth=6)\n",
    "print(model_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 20000\n",
    "patience = n_epochs//100\n",
    "\n",
    "batch_size = 512\n",
    "optimizer, optimizer_param = optimizer_param_dict[\"Adam\"]\n",
    "dataset_path = f\"dataset/processed_concat_data_{args.class_num}_labels\"\n",
    "\n",
    "log_save_dir = \"lightning_logs\"\n",
    "log_save_name = f\"15.1_enc_classify/{args.model_name}-{args.class_num}-{args.train_limit_data}-{args.random_seed}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_module = ALDataModule_v1.load_from_checkpoint(args.AE_ckpt_path)\n",
    "data_module.limit_and_set_train_data(data_module._train_data, data_module._train_label, limit_number=args.train_limit_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L.seed_everything(args.random_seed)\n",
    "\n",
    "net = AE1DMaxPoolBNClassifierModel(\n",
    "    AE1DMaxPoolBN_ckpt_path=args.AE_ckpt_path,\n",
    "    optimizer = optimizer,\n",
    "    optimizer_param = optimizer_param, \n",
    "    linear_channel_param = enc_linear_param_dict[args.linear_param],\n",
    "    out_features=8,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\" ----------------------start training---------------------------\")\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "from lightning.pytorch.loggers import TensorBoardLogger, CSVLogger\n",
    "from lightning.pytorch.utilities.model_summary import ModelSummary\n",
    "\n",
    "tensorboard_logger = TensorBoardLogger(save_dir=log_save_dir, name=log_save_name,)\n",
    "csv_logger = CSVLogger(save_dir=log_save_dir, name=log_save_name,)\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=None,\n",
    "    save_top_k=1,\n",
    "    monitor=\"val_loss\",\n",
    "    mode=\"min\",\n",
    "    filename=\"sample_{epoch:02d}-{step:02d}-{val_loss:02f}\"\n",
    ")\n",
    "\n",
    "trainer = L.Trainer(\n",
    "    logger=[tensorboard_logger, csv_logger],\n",
    "    callbacks=[EarlyStopping(monitor=\"val_loss\", patience=patience), checkpoint_callback],\n",
    "    max_epochs=n_epochs,\n",
    "    check_val_every_n_epoch=10,\n",
    "    accelerator=\"gpu\", \n",
    "    devices=4, \n",
    "    strategy=\"ddp\"\n",
    "    )\n",
    "\n",
    "trainer.fit(model=net, datamodule=data_module)\n",
    "trainer_test_dict = trainer.logged_metrics\n",
    "\n",
    "trainer.test(model=net, datamodule=data_module)\n",
    "trainer_test_dict.update(trainer.logged_metrics)\n",
    "\n",
    "for key in trainer_test_dict.keys():\n",
    "    trainer_test_dict[key] = trainer_test_dict[key].item()\n",
    "\n",
    "with open(os.path.join(trainer.logger.log_dir, \"result.json\"), \"w\") as f:\n",
    "    json.dump(trainer_test_dict, f)\n",
    "\n",
    "with open(os.path.join(trainer.logger.log_dir, \"argparse_params.json\"), \"w\") as f:\n",
    "    json.dump(args.__dict__, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"/nfs/ksdata/tran/HAR_AE/lightning_logs/15.1_enc_classify/4cnn_64-8-1000-64-8-1000-42/version_0/checkpoints/sample_epoch=599-step=2400-val_loss=0.636736.ckpt\"\n",
    "\n",
    "data_module = ALDataModule_v1.load_from_checkpoint(checkpoint_path)\n",
    "data_module.set_normal_train()\n",
    "net = AE1DMaxPoolBNClassifierModel.load_from_checkpoint(checkpoint_path)\n",
    "\n",
    "trainer = L.Trainer()\n",
    "\n",
    "trainer.test(model=net, datamodule=data_module)\n",
    "output = trainer.predict(model=net, datamodule=data_module)\n",
    "pred = torch.argmax(torch.concat(output), dim=1)\n",
    "gt = list(map(lambda x: x[1], iter(data_module.test_dataloader())))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
