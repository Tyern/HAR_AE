{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\1001002996\\AppData\\Local\\miniconda3\\Lib\\site-packages\\torchaudio\\backend\\utils.py:74: UserWarning: No audio backend is available.\n",
      "  warnings.warn(\"No audio backend is available.\")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import lightning as L\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from data_module.data_module import DefaultDataModule\n",
    "from model.classifier_model import Classifier1DRaw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST = False\n",
    "\n",
    "random_seed = 42\n",
    "raw_lin_gyr_dataset_path = \"dataset/raw_data_lin_gyr\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_stacked.shape (6, 196072, 500)\n",
      "data_stacked.shape (196072, 6, 500)\n"
     ]
    }
   ],
   "source": [
    "flag = 0\n",
    "\n",
    "if not os.path.isdir(raw_lin_gyr_dataset_path):\n",
    "    os.makedirs(raw_lin_gyr_dataset_path)\n",
    "    data_key = [\"LAcc_x\", \"LAcc_y\", \"LAcc_z\", \"Gyr_x\", \"Gyr_y\", \"Gyr_z\"]\n",
    "\n",
    "    data_path_dict = dict(zip(data_key, \n",
    "        [os.path.join(\"dataset\", \"Torso\", \"LAcc_x.txt\"),\n",
    "        os.path.join(\"dataset\", \"Torso\", \"LAcc_y.txt\"),\n",
    "        os.path.join(\"dataset\", \"Torso\", \"LAcc_z.txt\"),\n",
    "        os.path.join(\"dataset\", \"Torso\", \"Gyr_x.txt\"),\n",
    "        os.path.join(\"dataset\", \"Torso\", \"Gyr_y.txt\"),\n",
    "        os.path.join(\"dataset\", \"Torso\", \"Gyr_z.txt\"),]))\n",
    "    \n",
    "    data_stacked_list = []\n",
    "\n",
    "    for data_name in data_key:\n",
    "        one_data = np.loadtxt(data_path_dict[data_name])\n",
    "        data_stacked_list.append(one_data)\n",
    "\n",
    "    data_stacked = np.stack(data_stacked_list)\n",
    "    print(\"data_stacked.shape\", data_stacked.shape)\n",
    "\n",
    "    data_stacked = data_stacked.transpose(1, 0, 2)\n",
    "    print(\"data_stacked.shape\", data_stacked.shape)\n",
    "    \n",
    "    np.save(os.path.join(raw_lin_gyr_dataset_path, \"torso_lin_gyr.npy\") ,data_stacked)\n",
    "\n",
    "    label_path = os.path.join(\"dataset\", \"Torso\", \"Label.txt\")\n",
    "    label = np.loadtxt(label_path)\n",
    "    np.save(os.path.join(raw_lin_gyr_dataset_path, \"torso_label.npy\"), label)\n",
    "    flag = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label_idx [ True  True  True ...  True  True  True]\n",
      "train_data.shape, train_label.shape (156392, 6, 500) (156392,)\n",
      "val_data.shape, val_label.shape (19549, 6, 500) (19549,)\n",
      "test_data.shape, test_label.shape (19550, 6, 500) (19550,)\n"
     ]
    }
   ],
   "source": [
    "if flag == 1:\n",
    "    \n",
    "    from sklearn.model_selection import train_test_split\n",
    "    TRAIN_SIZE, VAL_SIZE, TEST_SIZE = 0.8, 0.1, 0.1\n",
    "    \n",
    "    train_file = os.path.join(raw_lin_gyr_dataset_path, \"torso_lin_gyr.npy\")\n",
    "    label_file = os.path.join(raw_lin_gyr_dataset_path, \"torso_label.npy\")\n",
    "\n",
    "    train_data = np.load(train_file)\n",
    "    label_data = np.load(label_file)\n",
    "\n",
    "    train_file = os.path.join(raw_lin_gyr_dataset_path, \"torso_train.npy\")\n",
    "    val_file = os.path.join(raw_lin_gyr_dataset_path, \"torso_val.npy\")\n",
    "    test_file = os.path.join(raw_lin_gyr_dataset_path, \"torso_test.npy\")\n",
    "\n",
    "    label_train_file = os.path.join(raw_lin_gyr_dataset_path, \"torso_train_label.npy\")\n",
    "    label_val_file = os.path.join(raw_lin_gyr_dataset_path, \"torso_val_label.npy\")\n",
    "    label_test_file = os.path.join(raw_lin_gyr_dataset_path, \"torso_test_label.npy\")\n",
    "\n",
    "    activity_range = list(range(1, 8+1))\n",
    "\n",
    "    label_idx = np.array([not any(x - x[0]) for x in label_data])\n",
    "    print(\"label_idx\", label_idx)\n",
    "\n",
    "    data_filtered = train_data[label_idx]\n",
    "    label_filtered = label_data[label_idx]\n",
    "\n",
    "    label = label_filtered[:, 0]\n",
    "\n",
    "    train_val_data, test_data, train_val_label, test_label = \\\n",
    "        train_test_split(data_filtered, label, test_size=TEST_SIZE, stratify=label, shuffle=True)\n",
    "\n",
    "    train_data, val_data, train_label, val_label = \\\n",
    "        train_test_split(train_val_data, train_val_label, test_size=VAL_SIZE / (TRAIN_SIZE + VAL_SIZE), stratify=train_val_label, shuffle=True)\n",
    "\n",
    "    print(\"train_data.shape, train_label.shape\", train_data.shape, train_label.shape)\n",
    "    print(\"val_data.shape, val_label.shape\", val_data.shape, val_label.shape)\n",
    "    print(\"test_data.shape, test_label.shape\", test_data.shape, test_label.shape)\n",
    "\n",
    "    np.save(train_file, train_data)\n",
    "    np.save(label_train_file, train_label)\n",
    "    np.save(val_file, val_data)\n",
    "    np.save(label_val_file, val_label)\n",
    "    np.save(test_file, test_data)\n",
    "    np.save(label_test_file, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   | Name     | Type        | Params | In sizes      | Out sizes    \n",
      "--------------------------------------------------------------------------\n",
      "0  | cnn      | Sequential  | 18.0 K | [10, 6, 500]  | [10, 64, 53] \n",
      "1  | cnn.0    | Conv1d      | 1.6 K  | [10, 6, 500]  | [10, 32, 165]\n",
      "2  | cnn.1    | ReLU        | 0      | [10, 32, 165] | [10, 32, 165]\n",
      "3  | cnn.2    | Dropout     | 0      | [10, 32, 165] | [10, 32, 165]\n",
      "4  | cnn.3    | Conv1d      | 16.4 K | [10, 32, 165] | [10, 64, 53] \n",
      "5  | cnn.4    | ReLU        | 0      | [10, 64, 53]  | [10, 64, 53] \n",
      "6  | cnn.5    | Dropout     | 0      | [10, 64, 53]  | [10, 64, 53] \n",
      "7  | linear   | Sequential  | 903 K  | [10, 3392]    | [10, 8]      \n",
      "8  | linear.0 | Linear      | 868 K  | [10, 3392]    | [10, 256]    \n",
      "9  | linear.1 | BatchNorm1d | 512    | [10, 256]     | [10, 256]    \n",
      "10 | linear.2 | ReLU        | 0      | [10, 256]     | [10, 256]    \n",
      "11 | linear.3 | Linear      | 32.9 K | [10, 256]     | [10, 128]    \n",
      "12 | linear.4 | BatchNorm1d | 256    | [10, 128]     | [10, 128]    \n",
      "13 | linear.5 | ReLU        | 0      | [10, 128]     | [10, 128]    \n",
      "14 | linear.6 | Linear      | 1.0 K  | [10, 128]     | [10, 8]      \n",
      "--------------------------------------------------------------------------\n",
      "921 K     Trainable params\n",
      "0         Non-trainable params\n",
      "921 K     Total params\n",
      "3.685     Total estimated model params size (MB)\n"
     ]
    }
   ],
   "source": [
    "from lightning.pytorch.utilities.model_summary import ModelSummary\n",
    "\n",
    "net = Classifier1DRaw(\n",
    "    optimizer=optim.SGD,\n",
    "    optimizer_param={\n",
    "        \"learning_rate\": 0.01,\n",
    "        \"momentum\": 0.5,\n",
    "    }, \n",
    "    cnn_channel_param = [\n",
    "        (6, 32, 8, 0, 3),\n",
    "        (32, 64, 8, 0, 3)\n",
    "    ],\n",
    "    linear_channel_param = [\n",
    "        256, 128\n",
    "    ]).to(\"cpu\")\n",
    "\n",
    "model_summary = ModelSummary(net, max_depth=6)\n",
    "print(model_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 20000\n",
    "patience = n_epochs//100\n",
    "\n",
    "optimizer_param_dict = {\n",
    "    \"Adam\": (optim.Adam, {\n",
    "        \"lr\": 0.001,\n",
    "    }),\n",
    "    \"SGD\": (optim.SGD, {\n",
    "        \"lr\": 0.001,\n",
    "        \"momentum\": 0.5,\n",
    "    }),\n",
    "}\n",
    "optimizer, optimizer_param = optimizer_param_dict[\"Adam\"]\n",
    "dataset_path = raw_lin_gyr_dataset_path\n",
    "\n",
    "log_save_dir = \"lightning_logs\"\n",
    "log_save_name = \"09_raw_lin_gyr\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\" ----------------------start training---------------------------\")\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "from lightning.pytorch.loggers import TensorBoardLogger, CSVLogger\n",
    "\n",
    "tensorboard_logger = TensorBoardLogger(save_dir=log_save_dir, name=log_save_name,)\n",
    "csv_logger = CSVLogger(save_dir=log_save_dir, name=log_save_name,)\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=None,\n",
    "    save_top_k=1,\n",
    "    monitor=\"val_loss\",\n",
    "    mode=\"min\",\n",
    "    filename=\"sample_{epoch:02d}-{step:02d}-{val_loss:02f}\"\n",
    ")\n",
    "\n",
    "trainer = L.Trainer(\n",
    "    logger=[tensorboard_logger, csv_logger],\n",
    "    callbacks=[EarlyStopping(monitor=\"val_loss\", patience=patience), checkpoint_callback],\n",
    "    max_epochs=n_epochs,\n",
    "    check_val_every_n_epoch=10,\n",
    "    accelerator=\"gpu\", \n",
    "    devices=4, \n",
    "    strategy=\"ddp\"\n",
    "    )\n",
    "\n",
    "net = Classifier1DRaw(\n",
    "    optimizer = optimizer,\n",
    "    optimizer_param = optimizer_param, \n",
    "    cnn_channel_param = [\n",
    "        (6, 32, 8, 0, 3),\n",
    "        (32, 64, 8, 0, 3)\n",
    "    ],\n",
    "    linear_channel_param = [\n",
    "        256, 128\n",
    "    ],\n",
    ")\n",
    "\n",
    "data_module = DefaultDataModule(dataset_path=raw_lin_gyr_dataset_path, batch_size=8192, prefix=\"torso_\")\n",
    "\n",
    "trainer.fit(model=net, datamodule=data_module)\n",
    "trainer.test(model=net, datamodule=data_module)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
