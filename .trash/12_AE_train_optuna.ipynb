{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import lightning as L\n",
    "\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "from lightning.pytorch.loggers import TensorBoardLogger, CSVLogger\n",
    "from lightning.pytorch.utilities.model_summary import ModelSummary\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from data_module.data_module import FFTDataModule\n",
    "from model.AE_model import AECNN1DModel\n",
    "\n",
    "import optuna\n",
    "from optuna.integration.pytorch_lightning import PyTorchLightningPruningCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEST = True\n",
    "\n",
    "random_seed = 42\n",
    "L.seed_everything(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 2000\n",
    "patience = n_epochs//10\n",
    "\n",
    "optimizer_param_dict = {\n",
    "    \"Adam\": (optim.Adam, {\n",
    "        \"lr\": 0.001,\n",
    "    }),\n",
    "    \"SGD\": (optim.SGD, {\n",
    "        \"lr\": 0.001,\n",
    "        \"momentum\": 0.5,\n",
    "    }),\n",
    "}\n",
    "batch_size = 512\n",
    "optimizer, optimizer_param = optimizer_param_dict[\"Adam\"]\n",
    "dataset_path = \"/nfs/ksdata/tran/HAR_AE/dataset/processed_concat_data\"\n",
    "\n",
    "log_save_dir = \"lightning_logs\"\n",
    "log_save_name = \"12_AE_train_optuna5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def objective(trial):\n",
    "    kernel_size = trial.suggest_categorical(\"kernel_size\", [6, 8, 11, 15])\n",
    "    first_cnn_filter = trial.suggest_int(\"first_cnn_filter\", 5, 7)\n",
    "    last_linear_input = trial.suggest_int(\"last_linear_input\", 5, 8)\n",
    "    cnn_layer_num = trial.suggest_int(\"cnn_layer_num\", 1, 4)\n",
    "    linear_layer_num = trial.suggest_int(\"linear_layer_num\", 1, 4)\n",
    "\n",
    "    trainer = L.Trainer(\n",
    "        default_root_dir=os.path.join(log_save_dir, log_save_name),\n",
    "        max_epochs=n_epochs,\n",
    "        callbacks=[EarlyStopping(monitor=\"val_mse\", patience=patience)],\n",
    "        enable_checkpointing=False,\n",
    "        accelerator=\"auto\",\n",
    "        check_val_every_n_epoch=100,\n",
    "        )\n",
    "\n",
    "    cnn_channel_param = []\n",
    "    input_channel = 6\n",
    "    for i in range(cnn_layer_num):\n",
    "        cnn_channel_param.append((input_channel, 2 ** (first_cnn_filter + i), kernel_size, 0, 3))\n",
    "        input_channel = 2 ** (first_cnn_filter + i)\n",
    "\n",
    "    linear_channel_param = []\n",
    "    for i in range(linear_layer_num):\n",
    "        linear_channel_param.insert(0, 2 ** (last_linear_input + i))\n",
    "\n",
    "    net = AECNN1DModel(\n",
    "        optimizer = optimizer,\n",
    "        optimizer_param = optimizer_param, \n",
    "        cnn_channel_param = cnn_channel_param,\n",
    "        linear_channel_param = linear_channel_param,\n",
    "    )\n",
    "\n",
    "    model_summary = ModelSummary(net, max_depth=6)\n",
    "    print(\"model_summary\", model_summary)\n",
    "\n",
    "    data_module = FFTDataModule(dataset_path=dataset_path, batch_size=batch_size)\n",
    "\n",
    "    trainer.fit(model=net, datamodule=data_module)\n",
    "\n",
    "    trainer_test_dict = trainer.logged_metrics\n",
    "    return trainer_test_dict[\"val_mse\"].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pruner: optuna.pruners.BasePruner = (optuna.pruners.MedianPruner())\n",
    "\n",
    "study = optuna.create_study(direction=\"minimize\", pruner=pruner)\n",
    "study.optimize(objective, n_trials=50, n_jobs=6)\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "for key, val in trial.params.items():\n",
    "    print(\"{}: {}\".format(key, val))\n",
    "\n",
    "with open(os.path.join(log_save_dir, log_save_name, \"optuna_params.json\"), \"w\") as f:\n",
    "    json.dump(dict(trial.params), f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ce20693ee18325632b860fb71df90bb6db110e9db4cb480753762aeffe35e52c"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
