{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\1001002996\\AppData\\Local\\miniconda3\\Lib\\site-packages\\torchaudio\\backend\\utils.py:74: UserWarning: No audio backend is available.\n",
      "  warnings.warn(\"No audio backend is available.\")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import lightning as L\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from data_module.data_module import FFTDataModule\n",
    "from model.AE_model import AE1D_simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEST = True\n",
    "\n",
    "random_seed = 42\n",
    "fft_dir_path = \"dataset/processed_data\"\n",
    "\n",
    "L.seed_everything(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TEST:\n",
    "    data_module = FFTDataModule(dataset_path=fft_dir_path)\n",
    "    data_module.setup()\n",
    "\n",
    "    print(len(data_module.train_set))\n",
    "    print(len(data_module.val_set))\n",
    "    print(len(data_module.test_set))\n",
    "\n",
    "    val_loader = data_module.val_dataloader()\n",
    "    print(next(iter(val_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   | Name         | Type            | Params | In sizes     | Out sizes   \n",
      "--------------------------------------------------------------------------------\n",
      "0  | encoder      | Sequential      | 18.0 K | [10, 6, 257] | [10, 64, 26]\n",
      "1  | encoder.0    | Conv1d          | 1.6 K  | [10, 6, 257] | [10, 32, 84]\n",
      "2  | encoder.1    | ReLU            | 0      | [10, 32, 84] | [10, 32, 84]\n",
      "3  | encoder.2    | Dropout         | 0      | [10, 32, 84] | [10, 32, 84]\n",
      "4  | encoder.3    | Conv1d          | 16.4 K | [10, 32, 84] | [10, 64, 26]\n",
      "5  | encoder.4    | ReLU            | 0      | [10, 64, 26] | [10, 64, 26]\n",
      "6  | encoder.5    | Dropout         | 0      | [10, 64, 26] | [10, 64, 26]\n",
      "7  | enc_linear   | Sequential      | 2.0 M  | [10, 1664]   | [10, 256]   \n",
      "8  | enc_linear.0 | Linear          | 1.7 M  | [10, 1664]   | [10, 1024]  \n",
      "9  | enc_linear.1 | ReLU            | 0      | [10, 1024]   | [10, 1024]  \n",
      "10 | enc_linear.2 | Linear          | 262 K  | [10, 1024]   | [10, 256]   \n",
      "11 | dec_linear   | Sequential      | 2.0 M  | [10, 256]    | [10, 1664]  \n",
      "12 | dec_linear.0 | Linear          | 263 K  | [10, 256]    | [10, 1024]  \n",
      "13 | dec_linear.1 | ReLU            | 0      | [10, 1024]   | [10, 1024]  \n",
      "14 | dec_linear.2 | Linear          | 1.7 M  | [10, 1024]   | [10, 1664]  \n",
      "15 | decoder      | Sequential      | 18.0 K | [10, 64, 26] | [10, 6, 257]\n",
      "16 | decoder.0    | ConvTranspose1d | 16.4 K | [10, 64, 26] | [10, 32, 84]\n",
      "17 | decoder.1    | ReLU            | 0      | [10, 32, 84] | [10, 32, 84]\n",
      "18 | decoder.2    | ConvTranspose1d | 1.5 K  | [10, 32, 84] | [10, 6, 257]\n",
      "--------------------------------------------------------------------------------\n",
      "4.0 M     Trainable params\n",
      "0         Non-trainable params\n",
      "4.0 M     Total params\n",
      "15.888    Total estimated model params size (MB)\n"
     ]
    }
   ],
   "source": [
    "if TEST:\n",
    "    from lightning.pytorch.utilities.model_summary import ModelSummary\n",
    "\n",
    "    net = AE1D_simple(\n",
    "        optimizer=optim.SGD,\n",
    "        optimizer_param={\n",
    "            \"learning_rate\": 0.01,\n",
    "            \"momentum\": 0.5,\n",
    "        })\n",
    "    model_summary = ModelSummary(net, max_depth=6)\n",
    "\n",
    "    print(model_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 10000\n",
    "patience = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ----------------------start training---------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3060') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "Missing logger folder: lightning_logs\\AE1D\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\1001002996\\AppData\\Local\\miniconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\1001002996\\AppData\\Local\\miniconda3\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:639: Checkpoint directory C:\\Users\\1001002996\\Documents\\AE\\lightning_logs exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name       | Type       | Params | In sizes     | Out sizes   \n",
      "------------------------------------------------------------------------\n",
      "0 | encoder    | Sequential | 18.0 K | [10, 6, 257] | [10, 64, 26]\n",
      "1 | enc_linear | Sequential | 2.0 M  | [10, 1664]   | [10, 256]   \n",
      "2 | dec_linear | Sequential | 2.0 M  | [10, 256]    | [10, 1664]  \n",
      "3 | decoder    | Sequential | 18.0 K | [10, 64, 26] | [10, 6, 257]\n",
      "------------------------------------------------------------------------\n",
      "4.0 M     Trainable params\n",
      "0         Non-trainable params\n",
      "4.0 M     Total params\n",
      "15.888    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\1001002996\\AppData\\Local\\miniconda3\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "c:\\Users\\1001002996\\AppData\\Local\\miniconda3\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2:   1%|          | 3/306 [00:00<00:04, 75.43it/s, v_num=0, train_mse=0.0645]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\1001002996\\AppData\\Local\\miniconda3\\Lib\\site-packages\\lightning\\pytorch\\trainer\\call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "c:\\Users\\1001002996\\AppData\\Local\\miniconda3\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 39/39 [00:00<00:00, 194.39it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_mse            0.06475704908370972\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_mse': 0.06475704908370972}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\" ----------------------start training---------------------------\")\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "from lightning.pytorch.loggers import TensorBoardLogger, CSVLogger\n",
    "\n",
    "tensorboard_logger = TensorBoardLogger(\n",
    "    save_dir=\"lightning_logs\",\n",
    "    name=\"AE1D_lin_gyr\",\n",
    ")\n",
    "\n",
    "csv_logger = CSVLogger(\n",
    "    save_dir=\"lightning_logs\",\n",
    "    name=\"AE1D_lin_gyr\",\n",
    ")\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=None,\n",
    "    save_top_k=1,\n",
    "    monitor=\"val_mse\",\n",
    "    mode=\"min\",\n",
    "    filename=\"sample_{epoch:02d}-{step:02d}-{val_mse:02f}\"\n",
    ")\n",
    "\n",
    "trainer = L.Trainer(\n",
    "    logger=[tensorboard_logger, csv_logger],\n",
    "    callbacks=[EarlyStopping(monitor=\"val_mse\", patience=patience), checkpoint_callback],\n",
    "    max_epochs=n_epochs,\n",
    "    check_val_every_n_epoch=10\n",
    "    # fast_dev_run=True,\n",
    "    )\n",
    "\n",
    "net = AE1D_simple(\n",
    "    optimizer=optim.SGD,\n",
    "    optimizer_param={\n",
    "        \"learning_rate\": 0.01,\n",
    "        \"momentum\": 0.5,\n",
    "    })\n",
    "data_module = FFTDataModule(dataset_path=fft_dir_path, batch_size=8192)\n",
    "\n",
    "trainer.fit(model=net, datamodule=data_module)\n",
    "trainer.test(model=net, datamodule=data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
